{
    "model_id": "f0d84600-64be-4066-bb19-d4edbcca443e",
    "train_accuracy": [
        0.13787761425251743,
        0.15956622773044152,
        0.14794732765298219,
        0.15104570100697134,
        0.1680867544539117,
        0.1735089078233927,
        0.17118512780790085,
        0.19984508133230056,
        0.21378776142525174,
        0.21301316808675447,
        0.2300542215336948,
        0.22153369481022464,
        0.24012393493415957,
        0.24632068164213788,
        0.25561580170410536,
        0.2509682416731216,
        0.2641363284275755,
        0.28272656855151046,
        0.27575522850503487,
        0.2858249419054996,
        0.3160340821068939,
        0.3075135553834237,
        0.3160340821068939,
        0.33230054221533695,
        0.3601859024012393,
        0.34624322230828813,
        0.3718048024786987,
        0.3493415956622773,
        0.39504260263361735,
        0.3803253292021689,
        0.39659178931061195,
        0.40123934934159566,
        0.41750580945003873,
        0.4384198295894655,
        0.4539116963594113
    ],
    "train_loss": [
        0.08452035843356463,
        0.08414550274495096,
        0.08395526124745907,
        0.08378948572529646,
        0.08338021234797471,
        0.08289315689450359,
        0.08276370290081045,
        0.08211719251066839,
        0.08131365476884554,
        0.08128867418982094,
        0.08086240393168052,
        0.08042626635775282,
        0.07943774017596965,
        0.07954115381913071,
        0.07874420767694734,
        0.0785055644377362,
        0.07782965801558137,
        0.07711656355839382,
        0.07757117497099175,
        0.07674492522785592,
        0.0751775822650546,
        0.07511453652548107,
        0.07422316009734233,
        0.07379994172628862,
        0.07249705335320104,
        0.07222061338210457,
        0.07106954990478563,
        0.07121946606684064,
        0.06964665046502785,
        0.0691051205214745,
        0.06934687557560265,
        0.06834395471051347,
        0.06768872948416807,
        0.06641205884429671,
        0.06579414160098335
    ],
    "val_accuracy": [
        0.15857605177993528,
        0.1715210355987055,
        0.20064724919093851,
        0.23300970873786409,
        0.2459546925566343,
        0.2459546925566343,
        0.284789644012945,
        0.2750809061488673,
        0.28802588996763756,
        0.2815533980582524,
        0.284789644012945,
        0.27184466019417475,
        0.27184466019417475,
        0.28802588996763756,
        0.29449838187702265,
        0.32038834951456313,
        0.31715210355987056,
        0.32362459546925565,
        0.33980582524271846,
        0.3559870550161812,
        0.3559870550161812,
        0.3559870550161812,
        0.36893203883495146,
        0.39158576051779936,
        0.37540453074433655,
        0.4110032362459547,
        0.4077669902912621,
        0.4174757281553398,
        0.39805825242718446,
        0.42394822006472493,
        0.4174757281553398,
        0.42718446601941745,
        0.4174757281553398,
        0.4336569579288026,
        0.44660194174757284
    ],
    "val_loss": [
        0.08726981079694136,
        0.08669433393138898,
        0.08618361587277508,
        0.08577841192387455,
        0.08539653827457366,
        0.08501886125521367,
        0.08454588045965893,
        0.08403127247461609,
        0.08349712882612902,
        0.08295323663544886,
        0.08257596431040841,
        0.08199681973380178,
        0.08153319397404742,
        0.08093377185870915,
        0.08044269709911162,
        0.08001114133878047,
        0.07955956188992003,
        0.07902194921252798,
        0.07852978922402588,
        0.07790559279494301,
        0.07737086197319154,
        0.0769676595058256,
        0.0763803110925125,
        0.07577585055218546,
        0.07533448143684363,
        0.07479479899298412,
        0.07440211819213571,
        0.07393220713223454,
        0.0734960924846069,
        0.07282795952361765,
        0.0722951827311593,
        0.07175225656009415,
        0.07118690746887602,
        0.07069026729435597,
        0.07012333569017429
    ],
    "hyperparameters": {
        "learning_rate": 1e-06,
        "num_epochs": 35,
        "batch_size": 25,
        "max_len": 150
    },
    "results": {
        "classes": 8,
        "last_acc": 0.44660194174757284,
        "best_acc": 0.44660194174757284,
        "best_acc_epoch": 34,
        "confusion_matrix": [
            [
                9,
                5,
                11,
                3,
                7,
                2,
                1,
                7
            ],
            [
                0,
                13,
                5,
                3,
                1,
                1,
                5,
                2
            ],
            [
                0,
                1,
                23,
                0,
                0,
                9,
                0,
                2
            ],
            [
                0,
                10,
                1,
                14,
                3,
                0,
                6,
                0
            ],
            [
                4,
                5,
                1,
                6,
                15,
                0,
                6,
                3
            ],
            [
                0,
                3,
                11,
                0,
                1,
                23,
                3,
                2
            ],
            [
                0,
                8,
                1,
                2,
                7,
                1,
                19,
                1
            ],
            [
                0,
                4,
                13,
                0,
                1,
                1,
                2,
                22
            ]
        ],
        "classification_report": "                           precision    recall  f1-score   support\n\n              flag_waving       0.69      0.20      0.31        45\nexaggeration,minimisation       0.27      0.43      0.33        30\ncausal_oversimplification       0.35      0.66      0.46        35\n    name_calling,labeling       0.50      0.41      0.45        34\n               repetition       0.43      0.38      0.40        40\n                    doubt       0.62      0.53      0.57        43\n          loaded_language       0.45      0.49      0.47        39\n appeal_to_fear_prejudice       0.56      0.51      0.54        43\n\n                 accuracy                           0.45       309\n                macro avg       0.48      0.45      0.44       309\n             weighted avg       0.50      0.45      0.44       309\n"
    }
}