{
    "model_id": "5e6b1a3c-b12c-4d06-87ef-a90eae819ee4",
    "train_accuracy": [
        0.18667699457784662,
        0.24786986831913246,
        0.3555383423702556,
        0.42137877614252517,
        0.533694810224632,
        0.6034082106893881,
        0.6607281177381874,
        0.726568551510457,
        0.8164213787761425,
        0.8675445391169636,
        0.8969790859798605,
        0.9295120061967467,
        0.9465530596436871,
        0.9604957397366383,
        0.9659178931061193,
        0.965143299767622,
        0.9767621998450813,
        0.9721146398140976,
        0.9783113865220759,
        0.9806351665375678,
        0.9821843532145623,
        0.981409759876065,
        0.9845081332300543,
        0.9860573199070488,
        0.9860573199070488,
        0.9876065065840434,
        0.9891556932610379,
        0.9852827265685515,
        0.9860573199070488,
        0.983733539891557,
        0.9852827265685515,
        0.9868319132455461,
        0.9852827265685515,
        0.9868319132455461,
        0.9860573199070488
    ],
    "train_loss": [
        0.08247242936046432,
        0.07863485573060193,
        0.07317007225119357,
        0.06790762073212497,
        0.06098081325025728,
        0.054454737675457755,
        0.04764634135340093,
        0.0399915297118201,
        0.032456829878454704,
        0.025687012120238762,
        0.021220174064754425,
        0.015994519503148,
        0.013127303442042711,
        0.010556098486359595,
        0.008964815596154639,
        0.0080342953930891,
        0.006833507756592228,
        0.0062756361302758815,
        0.005469238482225227,
        0.004854964919093965,
        0.0043469178645440905,
        0.003666221737676956,
        0.003403280423788208,
        0.003386409521841615,
        0.003059872366216735,
        0.0027513760672254585,
        0.002395705050860238,
        0.002632996107802938,
        0.002587271621991829,
        0.0026953947174165895,
        0.002166072453504196,
        0.0023727736844862276,
        0.002350475463084155,
        0.0022688979076655865,
        0.001996107728420349
    ],
    "val_accuracy": [
        0.2686084142394822,
        0.3268608414239482,
        0.39805825242718446,
        0.39805825242718446,
        0.44660194174757284,
        0.45307443365695793,
        0.47249190938511326,
        0.5631067961165048,
        0.6310679611650486,
        0.6213592233009708,
        0.6245954692556634,
        0.6440129449838188,
        0.6310679611650486,
        0.6601941747572816,
        0.6051779935275081,
        0.6310679611650486,
        0.6634304207119741,
        0.6537216828478964,
        0.6666666666666666,
        0.6601941747572816,
        0.6537216828478964,
        0.6407766990291263,
        0.6601941747572816,
        0.6601941747572816,
        0.6537216828478964,
        0.6504854368932039,
        0.6634304207119741,
        0.6440129449838188,
        0.6375404530744336,
        0.6213592233009708,
        0.6601941747572816,
        0.6375404530744336,
        0.6601941747572816,
        0.6407766990291263,
        0.6699029126213593
    ],
    "val_loss": [
        0.08314962873181093,
        0.07750209404041081,
        0.07345025786304166,
        0.06912249654627926,
        0.06509492003801957,
        0.06077817574288081,
        0.05624029744404419,
        0.05195749268948453,
        0.04848469827553215,
        0.047066910560077065,
        0.04611961413355707,
        0.045216722974499454,
        0.046754012794556356,
        0.04632840168128893,
        0.05003159273789538,
        0.04902958079063391,
        0.048645510642659706,
        0.04937402928145572,
        0.05148035056382707,
        0.050494474114723575,
        0.05269731306335301,
        0.05473281689060545,
        0.053370553698740344,
        0.05528172628779242,
        0.055235085363912736,
        0.055489391570723946,
        0.056394872349057,
        0.05684480003554458,
        0.0578867750646227,
        0.06027691071087488,
        0.05794419960682446,
        0.059275261020969035,
        0.05922194225502631,
        0.06217209941746733,
        0.06037816781442142
    ],
    "hyperparameters": {
        "learning_rate": 1e-05,
        "num_epochs": 35,
        "batch_size": 25,
        "max_len": 150
    },
    "results": {
        "classes": 8,
        "last_acc": 0.6699029126213593,
        "best_acc": 0.6699029126213593,
        "best_acc_epoch": 34,
        "confusion_matrix": [
            [
                34,
                1,
                3,
                0,
                0,
                2,
                0,
                5
            ],
            [
                2,
                17,
                0,
                0,
                2,
                0,
                7,
                2
            ],
            [
                2,
                2,
                23,
                0,
                0,
                4,
                0,
                4
            ],
            [
                1,
                4,
                0,
                21,
                3,
                1,
                4,
                0
            ],
            [
                4,
                3,
                0,
                3,
                26,
                1,
                2,
                1
            ],
            [
                3,
                0,
                5,
                0,
                2,
                29,
                3,
                1
            ],
            [
                0,
                3,
                0,
                1,
                7,
                1,
                26,
                1
            ],
            [
                1,
                4,
                4,
                0,
                1,
                1,
                1,
                31
            ]
        ],
        "classification_report": "                           precision    recall  f1-score   support\n\n              flag_waving       0.72      0.76      0.74        45\nexaggeration,minimisation       0.50      0.57      0.53        30\ncausal_oversimplification       0.66      0.66      0.66        35\n    name_calling,labeling       0.84      0.62      0.71        34\n               repetition       0.63      0.65      0.64        40\n                    doubt       0.74      0.67      0.71        43\n          loaded_language       0.60      0.67      0.63        39\n appeal_to_fear_prejudice       0.69      0.72      0.70        43\n\n                 accuracy                           0.67       309\n                macro avg       0.67      0.66      0.67       309\n             weighted avg       0.68      0.67      0.67       309\n"
    }
}