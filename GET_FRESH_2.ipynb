{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgQeo85Be63J",
        "outputId": "047ab605-1e31-4155-bbb9-04a6148690d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IN COLAB:  False\n"
          ]
        }
      ],
      "source": [
        "try :\n",
        "  from google.colab import drive\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "print('IN COLAB: ', IN_COLAB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "_jTOE1XIe63K",
        "outputId": "79dcee97-2733-4b3a-acd1-1f8944dfd18d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
            "  from pandas.core import (\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tagged_in_context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>causal_oversimplification</td>\n",
              "      <td>Mostly because &lt;BOS&gt; the country would not las...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>appeal_to_fear_prejudice</td>\n",
              "      <td>Lyndon Johnson &lt;BOS&gt; gets Earl Warren and Sen....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>repetition</td>\n",
              "      <td>It must be exacted from him directly in order ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>name_calling,labeling</td>\n",
              "      <td>Is it any wonder that priests and laity alike ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>loaded_language</td>\n",
              "      <td>Health workers have been asked to work with co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629</th>\n",
              "      <td>flag_waving</td>\n",
              "      <td>As a result, 58,177 &lt;BOS&gt; Americans &lt;EOS&gt; woul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>flag_waving</td>\n",
              "      <td>&lt;BOS&gt; But if you are a freedom-loving American...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>632</th>\n",
              "      <td>loaded_language</td>\n",
              "      <td>I heard lots of &lt;BOS&gt; gut-wrenching stories &lt;E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>638</th>\n",
              "      <td>flag_waving</td>\n",
              "      <td>&lt;BOS&gt; He also sang an Islamic State fight song...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>639</th>\n",
              "      <td>causal_oversimplification</td>\n",
              "      <td>We hear again, as we did incessantly from the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>309 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         label  \\\n",
              "1    causal_oversimplification   \n",
              "2     appeal_to_fear_prejudice   \n",
              "4                   repetition   \n",
              "5        name_calling,labeling   \n",
              "6              loaded_language   \n",
              "..                         ...   \n",
              "629                flag_waving   \n",
              "631                flag_waving   \n",
              "632            loaded_language   \n",
              "638                flag_waving   \n",
              "639  causal_oversimplification   \n",
              "\n",
              "                                     tagged_in_context  \n",
              "1    Mostly because <BOS> the country would not las...  \n",
              "2    Lyndon Johnson <BOS> gets Earl Warren and Sen....  \n",
              "4    It must be exacted from him directly in order ...  \n",
              "5    Is it any wonder that priests and laity alike ...  \n",
              "6    Health workers have been asked to work with co...  \n",
              "..                                                 ...  \n",
              "629  As a result, 58,177 <BOS> Americans <EOS> woul...  \n",
              "631  <BOS> But if you are a freedom-loving American...  \n",
              "632  I heard lots of <BOS> gut-wrenching stories <E...  \n",
              "638  <BOS> He also sang an Islamic State fight song...  \n",
              "639  We hear again, as we did incessantly from the ...  \n",
              "\n",
              "[309 rows x 2 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "parentdir = \"./propaganda_dataset_v2\"\n",
        "train_file= \"propaganda_train.tsv\"\n",
        "val_file= \"propaganda_val.tsv\"\n",
        "\n",
        "train_path=os.path.join(parentdir,train_file)\n",
        "val_path=os.path.join(parentdir,val_file)\n",
        "\n",
        "if IN_COLAB:\n",
        "  train_path = '/content/propaganda_train.tsv'\n",
        "  val_path = '/content/propaganda_val.tsv'\n",
        "\n",
        "train_df=pd.read_csv(train_path,delimiter=\"\\t\",quotechar='|')\n",
        "val_df=pd.read_csv(val_path,delimiter=\"\\t\",quotechar='|')\n",
        "train_df = train_df.drop(train_df[train_df['label'] == 'not_propaganda'].index)\n",
        "val_df = val_df.drop(val_df[val_df['label'] == 'not_propaganda'].index)\n",
        "train_df\n",
        "val_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxBKV-woe63L",
        "outputId": "46d6ff94-d80c-4490-fe12-bfeb50f18121"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tagged_in_context</th>\n",
              "      <th>label_str</th>\n",
              "      <th>extract_no_tags</th>\n",
              "      <th>extract_with_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>causal_oversimplification</td>\n",
              "      <td>Mostly because &lt;BOS&gt; the country would not las...</td>\n",
              "      <td>2</td>\n",
              "      <td>the country would not last long without an out...</td>\n",
              "      <td>&lt;BOS&gt; the country would not last long without ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>appeal_to_fear_prejudice</td>\n",
              "      <td>Lyndon Johnson &lt;BOS&gt; gets Earl Warren and Sen....</td>\n",
              "      <td>7</td>\n",
              "      <td>gets Earl Warren and Sen. Richard Russel to jo...</td>\n",
              "      <td>&lt;BOS&gt; gets Earl Warren and Sen. Richard Russel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>repetition</td>\n",
              "      <td>It must be exacted from him directly in order ...</td>\n",
              "      <td>4</td>\n",
              "      <td>infidels</td>\n",
              "      <td>&lt;BOS&gt; infidels &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>name_calling,labeling</td>\n",
              "      <td>Is it any wonder that priests and laity alike ...</td>\n",
              "      <td>3</td>\n",
              "      <td>the \"gay lifestyle</td>\n",
              "      <td>&lt;BOS&gt; the \"gay lifestyle &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>loaded_language</td>\n",
              "      <td>Health workers have been asked to work with co...</td>\n",
              "      <td>6</td>\n",
              "      <td>devastating communities</td>\n",
              "      <td>&lt;BOS&gt; devastating communities &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629</th>\n",
              "      <td>flag_waving</td>\n",
              "      <td>As a result, 58,177 &lt;BOS&gt; Americans &lt;EOS&gt; woul...</td>\n",
              "      <td>0</td>\n",
              "      <td>Americans</td>\n",
              "      <td>&lt;BOS&gt; Americans &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>flag_waving</td>\n",
              "      <td>&lt;BOS&gt; But if you are a freedom-loving American...</td>\n",
              "      <td>0</td>\n",
              "      <td>But if you are a freedom-loving American</td>\n",
              "      <td>&lt;BOS&gt; But if you are a freedom-loving American...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>632</th>\n",
              "      <td>loaded_language</td>\n",
              "      <td>I heard lots of &lt;BOS&gt; gut-wrenching stories &lt;E...</td>\n",
              "      <td>6</td>\n",
              "      <td>gut-wrenching stories</td>\n",
              "      <td>&lt;BOS&gt; gut-wrenching stories &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>638</th>\n",
              "      <td>flag_waving</td>\n",
              "      <td>&lt;BOS&gt; He also sang an Islamic State fight song...</td>\n",
              "      <td>0</td>\n",
              "      <td>He also sang an Islamic State fight song and r...</td>\n",
              "      <td>&lt;BOS&gt; He also sang an Islamic State fight song...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>639</th>\n",
              "      <td>causal_oversimplification</td>\n",
              "      <td>We hear again, as we did incessantly from the ...</td>\n",
              "      <td>2</td>\n",
              "      <td>with whom, I guess, she has also no choice but...</td>\n",
              "      <td>&lt;BOS&gt; with whom, I guess, she has also no choi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>309 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         label  \\\n",
              "1    causal_oversimplification   \n",
              "2     appeal_to_fear_prejudice   \n",
              "4                   repetition   \n",
              "5        name_calling,labeling   \n",
              "6              loaded_language   \n",
              "..                         ...   \n",
              "629                flag_waving   \n",
              "631                flag_waving   \n",
              "632            loaded_language   \n",
              "638                flag_waving   \n",
              "639  causal_oversimplification   \n",
              "\n",
              "                                     tagged_in_context  label_str  \\\n",
              "1    Mostly because <BOS> the country would not las...          2   \n",
              "2    Lyndon Johnson <BOS> gets Earl Warren and Sen....          7   \n",
              "4    It must be exacted from him directly in order ...          4   \n",
              "5    Is it any wonder that priests and laity alike ...          3   \n",
              "6    Health workers have been asked to work with co...          6   \n",
              "..                                                 ...        ...   \n",
              "629  As a result, 58,177 <BOS> Americans <EOS> woul...          0   \n",
              "631  <BOS> But if you are a freedom-loving American...          0   \n",
              "632  I heard lots of <BOS> gut-wrenching stories <E...          6   \n",
              "638  <BOS> He also sang an Islamic State fight song...          0   \n",
              "639  We hear again, as we did incessantly from the ...          2   \n",
              "\n",
              "                                       extract_no_tags  \\\n",
              "1    the country would not last long without an out...   \n",
              "2    gets Earl Warren and Sen. Richard Russel to jo...   \n",
              "4                                             infidels   \n",
              "5                                   the \"gay lifestyle   \n",
              "6                              devastating communities   \n",
              "..                                                 ...   \n",
              "629                                          Americans   \n",
              "631           But if you are a freedom-loving American   \n",
              "632                              gut-wrenching stories   \n",
              "638  He also sang an Islamic State fight song and r...   \n",
              "639  with whom, I guess, she has also no choice but...   \n",
              "\n",
              "                                     extract_with_tags  \n",
              "1    <BOS> the country would not last long without ...  \n",
              "2    <BOS> gets Earl Warren and Sen. Richard Russel...  \n",
              "4                                 <BOS> infidels <EOS>  \n",
              "5                       <BOS> the \"gay lifestyle <EOS>  \n",
              "6                  <BOS> devastating communities <EOS>  \n",
              "..                                                 ...  \n",
              "629                              <BOS> Americans <EOS>  \n",
              "631  <BOS> But if you are a freedom-loving American...  \n",
              "632                  <BOS> gut-wrenching stories <EOS>  \n",
              "638  <BOS> He also sang an Islamic State fight song...  \n",
              "639  <BOS> with whom, I guess, she has also no choi...  \n",
              "\n",
              "[309 rows x 5 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "experiment = True\n",
        "\n",
        "def extract_tagged_section(row):\n",
        "    pattern = r'<BOS>.*?<EOS>'\n",
        "    match = re.search(pattern, row['tagged_in_context'])\n",
        "    return match.group() if match else \"\"\n",
        "\n",
        "def extract_text_inside_tags(row):\n",
        "    pattern = r'<BOS>(.*?)<EOS>'\n",
        "    match = re.search(pattern, row['tagged_in_context'])\n",
        "    return match.group(1).strip() if match else \"\"\n",
        "\n",
        "def transform_multi_label(row):\n",
        "    new_value = label_to_id[row['label']]\n",
        "    return new_value\n",
        "\n",
        "def transform_strip_tag(row):\n",
        "    sent = row['tagged_in_context']\n",
        "    cleaned_string = sent.replace(\"<BOS>\", \"\")\n",
        "    cleaned_string = cleaned_string.replace(\"<EOS>\", \"\")\n",
        "    return cleaned_string\n",
        "\n",
        "\n",
        "\n",
        "label_to_id = {'flag_waving': 0, 'exaggeration,minimisation': 1, 'causal_oversimplification': 2, 'name_calling,labeling': 3, 'repetition': 4, 'doubt': 5, 'loaded_language': 6, 'appeal_to_fear_prejudice': 7}\n",
        "id_to_label = {0: 'flag_waving', 1: 'exaggeration,minimisation', 2: 'causal_oversimplification', 3: 'name_calling,labeling', 4: 'repetition', 5: 'doubt',6: 'loaded_language', 7: 'appeal_to_fear_prejudice'}\n",
        "\n",
        "train_df['label_str'] = train_df.apply(transform_multi_label, axis=1)\n",
        "train_df['extract_no_tags'] = train_df.apply(extract_text_inside_tags, axis=1)\n",
        "train_df['extract_with_tags'] = train_df.apply(extract_tagged_section, axis=1)\n",
        "\n",
        "val_df['label_str'] = val_df.apply(transform_multi_label, axis=1)\n",
        "val_df['extract_no_tags'] = val_df.apply(extract_text_inside_tags, axis=1)\n",
        "val_df['extract_with_tags'] = val_df.apply(extract_tagged_section, axis=1)\n",
        "\n",
        "val_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# longest_string = val_df['extract_no_tags'].apply(lambda x: len(str(x))).max()\n",
        "# print(\"Longest string length:\", longest_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 24\n",
        "lr = 1e-5\n",
        "batch_size=25\n",
        "max_len=150\n",
        "n_classes = 8\n",
        "\n",
        "sent_col = 'extract_no_tags'\n",
        "target_col = 'label_str'\n",
        "\n",
        "# sent_col = 'extract_with_tags'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "K7bzFnN9e636"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "class CustomPropagandaDataset_vanilla(Dataset):\n",
        "    def __init__(self,df, max_len, sent_col, target_col):\n",
        "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.labels=torch.tensor([label for label in df[target_col]])\n",
        "        # print(self.labels)\n",
        "        self.texts=[tokenizer(text,padding='max_length',max_length=max_len,truncation=True,return_tensors=\"pt\") for text in df[sent_col]]\n",
        "        # print(self.texts)\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self,idx):\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self,idx):\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        batch_texts=self.get_batch_texts(idx)\n",
        "        batch_y=self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts,batch_y\n",
        "\n",
        "\n",
        "def prepare_inputs(input1,label,device):\n",
        "  label=label.to(device)\n",
        "  mask=input1['attention_mask'].to(device)\n",
        "  input_id=input1['input_ids'].squeeze(1).to(device)\n",
        "  return (input_id,mask,label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR-HtD2Oe637",
        "outputId": "a123fe17-523f-4190-fd88-2a59a06807e8"
      },
      "outputs": [],
      "source": [
        "train_data = CustomPropagandaDataset_vanilla(train_df, max_len, sent_col, target_col)\n",
        "val_data = CustomPropagandaDataset_vanilla(val_df, max_len, sent_col, target_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "M-1p-DlKe637"
      },
      "outputs": [],
      "source": [
        "train_dataloader=torch.utils.data.DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
        "val_dataloader=torch.utils.data.DataLoader(val_data,batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PD_sgNxe638",
        "outputId": "d273abd5-d012-456b-d2cf-e82c362b1634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self,dropout=0.5,num_classes=8):\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert=BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout=nn.Dropout(dropout)\n",
        "        self.linear=nn.Linear(768,num_classes)\n",
        "        self.relu=nn.ReLU()\n",
        "\n",
        "    def forward(self,input_id,mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids=input_id,attention_mask=mask,return_dict=False)\n",
        "        dropout_output=self.dropout(pooled_output)\n",
        "        linear_output=self.linear(dropout_output)\n",
        "        final_layer=self.relu(linear_output)\n",
        "\n",
        "        return final_layer\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ldwpXHKle638",
        "outputId": "65850600-ad12-41d7-b73e-60ff0a0095d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 52/52 [01:23<00:00,  1.61s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 1 | Train Loss: 0.084 | Train Accuracy: 0.148\n",
            "Val loss: 0.086 | Val Accuracy: 0.188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 7/52 [00:12<01:19,  1.76s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m     total_acc_train\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39macc\n\u001b[0;32m     40\u001b[0m     model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 41\u001b[0m     batch_loss_1\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     42\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     44\u001b[0m total_acc_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    524\u001b[0m )\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    267\u001b[0m     tensors,\n\u001b[0;32m    268\u001b[0m     grad_tensors_,\n\u001b[0;32m    269\u001b[0m     retain_graph,\n\u001b[0;32m    270\u001b[0m     create_graph,\n\u001b[0;32m    271\u001b[0m     inputs,\n\u001b[0;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m )\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import uuid\n",
        "\n",
        "\n",
        "model=BertClassifier(num_classes=8)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "train_acc_list = []\n",
        "train_loss_list = []\n",
        "val_acc_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "best_val_acc = 0\n",
        "best_epoch = 0\n",
        "best_model_state = None\n",
        "\n",
        "model_id = str(uuid.uuid4())\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "for epoch_num in range(epochs):\n",
        "        total_acc_train=0\n",
        "        total_loss_train=0\n",
        "        model.train()\n",
        "        for train_input,train_label in tqdm(train_dataloader):\n",
        "\n",
        "            input_id,mask, train_label=prepare_inputs(train_input,train_label,device)\n",
        "\n",
        "            output_1=model(input_id,mask)\n",
        "\n",
        "            batch_loss_1=criterion(output_1,train_label.long())\n",
        "            total_loss_train +=batch_loss_1.item()\n",
        "\n",
        "            acc=(output_1.argmax(dim=1)==train_label).sum().item()\n",
        "            total_acc_train+=acc\n",
        "\n",
        "            model.zero_grad()\n",
        "            batch_loss_1.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_acc_val=0\n",
        "        total_loss_val=0\n",
        "\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for val_input,val_label in val_dataloader:\n",
        "\n",
        "                input_id,mask, val_label=prepare_inputs(val_input,val_label,device)\n",
        "\n",
        "                output_2= model(input_id,mask)\n",
        "\n",
        "                # for scoring\n",
        "                predicted = output_2.argmax(dim=1)\n",
        "                y_true.extend(val_label.cpu().numpy())\n",
        "                y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "                batch_loss_2=criterion(output_2,val_label.long())\n",
        "\n",
        "                total_loss_val+=batch_loss_2.item()\n",
        "\n",
        "                acc=(output_2.argmax(dim=1)==val_label).sum().item()\n",
        "                total_acc_val+=acc\n",
        "            train_acc = total_acc_train / len(train_data)\n",
        "\n",
        "        train_loss = total_loss_train / len(train_data)\n",
        "        val_acc = total_acc_val / len(val_data)\n",
        "        val_loss = total_loss_val / len(val_data)\n",
        "\n",
        "        train_acc_list.append(train_acc)\n",
        "        train_loss_list.append(train_loss)\n",
        "        val_acc_list.append(val_acc)\n",
        "        val_loss_list.append(val_loss)\n",
        "\n",
        "        print(f'Epochs: {epoch_num+1} | Train Loss: {total_loss_train / len(train_data):.3f} | Train Accuracy: {total_acc_train/len(train_data):.3f}')\n",
        "        print(f'Val loss: {total_loss_val/len(val_data):.3f} | Val Accuracy: {total_acc_val / len(val_data):.3f}')\n",
        "        if val_acc > best_val_acc:\n",
        "          best_epoch = epoch_num\n",
        "          y_true_best = y_true.copy()\n",
        "          y_pred_best = y_pred.copy()\n",
        "          best_val_acc = val_acc\n",
        "          best_model_state = model.state_dict()\n",
        "\n",
        "        if epoch_num == epochs-1:\n",
        "            print(f'______{model_id}______')\n",
        "            print(f'LR: {lr} FINAL ACC = {total_acc_val / len(val_data):.3f}')\n",
        "            print(f'LR: {lr} BEST ACC = {best_val_acc:.3f}')\n",
        "            print('____________')\n",
        "\n",
        "\n",
        "# Plot the accuracy and loss curves over epochs\n",
        "epochs_range = range(1, epochs+1)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, train_acc_list, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc_list, label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Accuracy Curves')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, train_loss_list, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss_list, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Loss Curves')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CuQtO06Fe63-",
        "outputId": "f7870680-631d-44b3-bc82-0c86ab98c78c"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "too many positional arguments",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# analysis of best performing model\u001b[39;00m\n\u001b[0;32m      8\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(id_to_label\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m----> 9\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_true_best, y_pred_best, classes)\n\u001b[0;32m     11\u001b[0m disp \u001b[38;5;241m=\u001b[39m ConfusionMatrixDisplay(cm)\n\u001b[0;32m     12\u001b[0m disp\u001b[38;5;241m.\u001b[39mplot()\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[1;32m--> 189\u001b[0m params \u001b[38;5;241m=\u001b[39m func_sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    190\u001b[0m params\u001b[38;5;241m.\u001b[39mapply_defaults()\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\inspect.py:3212\u001b[0m, in \u001b[0;36mSignature.bind\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   3208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[0;32m   3209\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[0;32m   3210\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[0;32m   3211\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bind(args, kwargs)\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\inspect.py:3138\u001b[0m, in \u001b[0;36mSignature._bind\u001b[1;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[0;32m   3134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m (_VAR_KEYWORD, _KEYWORD_ONLY):\n\u001b[0;32m   3136\u001b[0m         \u001b[38;5;66;03m# Looks like we have no parameter for this positional\u001b[39;00m\n\u001b[0;32m   3137\u001b[0m         \u001b[38;5;66;03m# argument\u001b[39;00m\n\u001b[1;32m-> 3138\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   3139\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoo many positional arguments\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m _VAR_POSITIONAL:\n\u001b[0;32m   3142\u001b[0m         \u001b[38;5;66;03m# We have an '*args'-like argument, let's fill it with\u001b[39;00m\n\u001b[0;32m   3143\u001b[0m         \u001b[38;5;66;03m# all positional arguments we have left and move on to\u001b[39;00m\n\u001b[0;32m   3144\u001b[0m         \u001b[38;5;66;03m# the next phase\u001b[39;00m\n\u001b[0;32m   3145\u001b[0m         values \u001b[38;5;241m=\u001b[39m [arg_val]\n",
            "\u001b[1;31mTypeError\u001b[0m: too many positional arguments"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import json\n",
        "# analysis of best performing model\n",
        "classes = list(id_to_label.values())\n",
        "cm = confusion_matrix(y_true_best, y_pred_best)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(cm)\n",
        "disp.plot()\n",
        "\n",
        "# Compute precision, recall, F1-score, and other metrics for the best model\n",
        "report = classification_report(y_true_best, y_pred_best, target_names=classes)\n",
        "print('Classification Report:')\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YR-M6H7WhF63"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'cm' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 18\u001b[0m\n\u001b[0;32m      1\u001b[0m results_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_id\u001b[39m\u001b[38;5;124m'\u001b[39m: model_id,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: train_acc_list,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: train_loss_list,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: val_acc_list,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: val_loss_list,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyperparameters\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: lr,\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m: epochs,\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: batch_size,\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_len\u001b[39m\u001b[38;5;124m'\u001b[39m: max_len\n\u001b[0;32m     12\u001b[0m     },\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m\"\u001b[39m: n_classes,\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: val_acc_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_acc\u001b[39m\u001b[38;5;124m'\u001b[39m: best_val_acc,\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_acc_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m: best_epoch,\n\u001b[1;32m---> 18\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfusion_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m: cm\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification_report\u001b[39m\u001b[38;5;124m'\u001b[39m: report\n\u001b[0;32m     20\u001b[0m     }\n\u001b[0;32m     21\u001b[0m }\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Save the results dictionary as a JSON file with the model ID\u001b[39;00m\n\u001b[0;32m     25\u001b[0m results_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./results/multiclass_results_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'cm' is not defined"
          ]
        }
      ],
      "source": [
        "results_dict = {\n",
        "    'model_id': model_id,\n",
        "    'train_accuracy': train_acc_list,\n",
        "    'train_loss': train_loss_list,\n",
        "    'val_accuracy': val_acc_list,\n",
        "    'val_loss': val_loss_list,\n",
        "    'hyperparameters': {\n",
        "        'learning_rate': lr,\n",
        "        'num_epochs': epochs,\n",
        "        'batch_size': batch_size,\n",
        "        'max_len': max_len\n",
        "    },\n",
        "    'results': {\n",
        "        \"classes\": n_classes,\n",
        "        \"last_acc\": val_acc_list[-1],\n",
        "        'best_acc': best_val_acc,\n",
        "        'best_acc_epoch': best_epoch,\n",
        "        'confusion_matrix': cm.tolist(),\n",
        "        'classification_report': report\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "# Save the results dictionary as a JSON file with the model ID\n",
        "results_filename = f'./results/multiclass_results_{model_id}.json'\n",
        "with open(results_filename, 'w') as f:\n",
        "    json.dump(results_dict, f, indent=4)\n",
        "\n",
        "# Save the best model state with the model ID\n",
        "model_filename = f'./results/multiclass_best_model_{model_id}.pth'\n",
        "torch.save(best_model_state, model_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
