{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN COLAB:  False\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "  from google.colab import drive\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "print('IN COLAB: ', IN_COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tagged_in_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>On average, between 300 and 600 infections are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>causal_oversimplification</td>\n",
       "      <td>Mostly because &lt;BOS&gt; the country would not las...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>appeal_to_fear_prejudice</td>\n",
       "      <td>Lyndon Johnson &lt;BOS&gt; gets Earl Warren and Sen....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>&lt;BOS&gt; You &lt;EOS&gt; may opt out at anytime.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>repetition</td>\n",
       "      <td>It must be exacted from him directly in order ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>NewsCatholic Church, &lt;BOS&gt; Family, Marriage &lt;E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>Remember our saying, modern day fairy &lt;BOS&gt; ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>Why &lt;BOS&gt; not &lt;EOS&gt; open up to Iran with massi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>flag_waving</td>\n",
       "      <td>&lt;BOS&gt; He also sang an Islamic State fight song...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>causal_oversimplification</td>\n",
       "      <td>We hear again, as we did incessantly from the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         label  \\\n",
       "0               not_propaganda   \n",
       "1    causal_oversimplification   \n",
       "2     appeal_to_fear_prejudice   \n",
       "3               not_propaganda   \n",
       "4                   repetition   \n",
       "..                         ...   \n",
       "635             not_propaganda   \n",
       "636             not_propaganda   \n",
       "637             not_propaganda   \n",
       "638                flag_waving   \n",
       "639  causal_oversimplification   \n",
       "\n",
       "                                     tagged_in_context  \n",
       "0    On average, between 300 and 600 infections are...  \n",
       "1    Mostly because <BOS> the country would not las...  \n",
       "2    Lyndon Johnson <BOS> gets Earl Warren and Sen....  \n",
       "3             <BOS> You <EOS> may opt out at anytime.   \n",
       "4    It must be exacted from him directly in order ...  \n",
       "..                                                 ...  \n",
       "635  NewsCatholic Church, <BOS> Family, Marriage <E...  \n",
       "636  Remember our saying, modern day fairy <BOS> ta...  \n",
       "637  Why <BOS> not <EOS> open up to Iran with massi...  \n",
       "638  <BOS> He also sang an Islamic State fight song...  \n",
       "639  We hear again, as we did incessantly from the ...  \n",
       "\n",
       "[640 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "parentdir = \"./propaganda_dataset_v2\"\n",
    "train_file= \"propaganda_train.tsv\"\n",
    "val_file= \"propaganda_val.tsv\"\n",
    "\n",
    "train_path=os.path.join(parentdir,train_file)\n",
    "val_path=os.path.join(parentdir,val_file)\n",
    "\n",
    "if IN_COLAB:\n",
    "  train_path = '/content/propaganda_train.tsv'\n",
    "  val_path = '/content/propaganda_val.tsv'\n",
    "\n",
    "train_df=pd.read_csv(train_path,delimiter=\"\\t\",quotechar='|')\n",
    "val_df=pd.read_csv(val_path,delimiter=\"\\t\",quotechar='|')\n",
    "\n",
    "train_df\n",
    "val_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tagged_in_context</th>\n",
       "      <th>label_str</th>\n",
       "      <th>extract_no_tags</th>\n",
       "      <th>extract_with_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>On average, between 300 and 600 infections are...</td>\n",
       "      <td>6</td>\n",
       "      <td>according to a UN estimate.</td>\n",
       "      <td>&lt;BOS&gt; according to a UN estimate. &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>causal_oversimplification</td>\n",
       "      <td>Mostly because &lt;BOS&gt; the country would not las...</td>\n",
       "      <td>2</td>\n",
       "      <td>the country would not last long without an out...</td>\n",
       "      <td>&lt;BOS&gt; the country would not last long without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>appeal_to_fear_prejudice</td>\n",
       "      <td>Lyndon Johnson &lt;BOS&gt; gets Earl Warren and Sen....</td>\n",
       "      <td>8</td>\n",
       "      <td>gets Earl Warren and Sen. Richard Russel to jo...</td>\n",
       "      <td>&lt;BOS&gt; gets Earl Warren and Sen. Richard Russel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>&lt;BOS&gt; You &lt;EOS&gt; may opt out at anytime.</td>\n",
       "      <td>6</td>\n",
       "      <td>You</td>\n",
       "      <td>&lt;BOS&gt; You &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>repetition</td>\n",
       "      <td>It must be exacted from him directly in order ...</td>\n",
       "      <td>4</td>\n",
       "      <td>infidels</td>\n",
       "      <td>&lt;BOS&gt; infidels &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>NewsCatholic Church, &lt;BOS&gt; Family, Marriage &lt;E...</td>\n",
       "      <td>6</td>\n",
       "      <td>Family, Marriage</td>\n",
       "      <td>&lt;BOS&gt; Family, Marriage &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>Remember our saying, modern day fairy &lt;BOS&gt; ta...</td>\n",
       "      <td>6</td>\n",
       "      <td>tales start with ‘once I am</td>\n",
       "      <td>&lt;BOS&gt; tales start with ‘once I am &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>Why &lt;BOS&gt; not &lt;EOS&gt; open up to Iran with massi...</td>\n",
       "      <td>6</td>\n",
       "      <td>not</td>\n",
       "      <td>&lt;BOS&gt; not &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>flag_waving</td>\n",
       "      <td>&lt;BOS&gt; He also sang an Islamic State fight song...</td>\n",
       "      <td>0</td>\n",
       "      <td>He also sang an Islamic State fight song and r...</td>\n",
       "      <td>&lt;BOS&gt; He also sang an Islamic State fight song...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>causal_oversimplification</td>\n",
       "      <td>We hear again, as we did incessantly from the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>with whom, I guess, she has also no choice but...</td>\n",
       "      <td>&lt;BOS&gt; with whom, I guess, she has also no choi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         label  \\\n",
       "0               not_propaganda   \n",
       "1    causal_oversimplification   \n",
       "2     appeal_to_fear_prejudice   \n",
       "3               not_propaganda   \n",
       "4                   repetition   \n",
       "..                         ...   \n",
       "635             not_propaganda   \n",
       "636             not_propaganda   \n",
       "637             not_propaganda   \n",
       "638                flag_waving   \n",
       "639  causal_oversimplification   \n",
       "\n",
       "                                     tagged_in_context  label_str  \\\n",
       "0    On average, between 300 and 600 infections are...          6   \n",
       "1    Mostly because <BOS> the country would not las...          2   \n",
       "2    Lyndon Johnson <BOS> gets Earl Warren and Sen....          8   \n",
       "3             <BOS> You <EOS> may opt out at anytime.           6   \n",
       "4    It must be exacted from him directly in order ...          4   \n",
       "..                                                 ...        ...   \n",
       "635  NewsCatholic Church, <BOS> Family, Marriage <E...          6   \n",
       "636  Remember our saying, modern day fairy <BOS> ta...          6   \n",
       "637  Why <BOS> not <EOS> open up to Iran with massi...          6   \n",
       "638  <BOS> He also sang an Islamic State fight song...          0   \n",
       "639  We hear again, as we did incessantly from the ...          2   \n",
       "\n",
       "                                       extract_no_tags  \\\n",
       "0                          according to a UN estimate.   \n",
       "1    the country would not last long without an out...   \n",
       "2    gets Earl Warren and Sen. Richard Russel to jo...   \n",
       "3                                                  You   \n",
       "4                                             infidels   \n",
       "..                                                 ...   \n",
       "635                                   Family, Marriage   \n",
       "636                        tales start with ‘once I am   \n",
       "637                                                not   \n",
       "638  He also sang an Islamic State fight song and r...   \n",
       "639  with whom, I guess, she has also no choice but...   \n",
       "\n",
       "                                     extract_with_tags  \n",
       "0              <BOS> according to a UN estimate. <EOS>  \n",
       "1    <BOS> the country would not last long without ...  \n",
       "2    <BOS> gets Earl Warren and Sen. Richard Russel...  \n",
       "3                                      <BOS> You <EOS>  \n",
       "4                                 <BOS> infidels <EOS>  \n",
       "..                                                 ...  \n",
       "635                       <BOS> Family, Marriage <EOS>  \n",
       "636            <BOS> tales start with ‘once I am <EOS>  \n",
       "637                                    <BOS> not <EOS>  \n",
       "638  <BOS> He also sang an Islamic State fight song...  \n",
       "639  <BOS> with whom, I guess, she has also no choi...  \n",
       "\n",
       "[640 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "label_to_id = {'flag_waving': 0, 'exaggeration,minimisation': 1, 'causal_oversimplification': 2, 'name_calling,labeling': 3, 'repetition': 4, 'doubt': 5, 'not_propaganda': 6, 'loaded_language': 7, 'appeal_to_fear_prejudice': 8}\n",
    "id_to_label = {0: 'flag_waving', 1: 'exaggeration,minimisation', 2: 'causal_oversimplification', 3: 'name_calling,labeling', 4: 'repetition', 5: 'doubt', 6: 'not_propaganda', 7: 'loaded_language', 8: 'appeal_to_fear_prejudice'}\n",
    "\n",
    "def extract_tagged_section(row):\n",
    "    pattern = r'<BOS>.*?<EOS>'\n",
    "    match = re.search(pattern, row['tagged_in_context'])\n",
    "    return match.group() if match else \"\"\n",
    "\n",
    "def extract_text_inside_tags(row):\n",
    "    pattern = r'<BOS>(.*?)<EOS>'\n",
    "    match = re.search(pattern, row['tagged_in_context'])\n",
    "    return match.group(1).strip() if match else \"\"\n",
    "\n",
    "def transform_multi_label(row):\n",
    "    new_value = label_to_id[row['label']]\n",
    "    return new_value\n",
    "\n",
    "def transform_strip_tag(row):\n",
    "    sent = row['tagged_in_context']\n",
    "    cleaned_string = sent.replace(\"<BOS>\", \"\")\n",
    "    cleaned_string = cleaned_string.replace(\"<EOS>\", \"\")\n",
    "    return cleaned_string\n",
    "\n",
    "\n",
    "train_df['label_str'] = train_df.apply(transform_multi_label, axis=1)\n",
    "# train_df['original_without_snip_tags'] = train_df.apply(transform_strip_tag, axis=1)\n",
    "train_df['extract_no_tags'] = train_df.apply(extract_text_inside_tags, axis=1)\n",
    "train_df['extract_with_tags'] = train_df.apply(extract_tagged_section, axis=1)\n",
    "\n",
    "val_df['label_str'] = val_df.apply(transform_multi_label, axis=1)\n",
    "val_df['extract_no_tags'] = val_df.apply(extract_text_inside_tags, axis=1)\n",
    "val_df['extract_with_tags'] = val_df.apply(extract_tagged_section, axis=1)\n",
    "# val_df['original_without_snip_tags'] = val_df.apply(transform_strip_tag, axis=1)\n",
    "\n",
    "train_df\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class CustomPropagandaDataset_vanilla(Dataset):\n",
    "    def __init__(self,df, sent_col, target_col):\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "        self.labels=torch.tensor([label for label in df[target_col]])\n",
    "        self.texts=[tokenizer(text,padding='max_length',max_length=150,truncation=True,return_tensors=\"pt\") for text in df[sent_col]]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self,idx):\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self,idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        batch_texts=self.get_batch_texts(idx)\n",
    "        batch_y=self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts,batch_y\n",
    "\n",
    "\n",
    "def prepare_inputs(input1,label,device):\n",
    "  label=label.to(device)\n",
    "  mask=input1['attention_mask'].to(device)\n",
    "  input_id=input1['input_ids'].squeeze(1).to(device)\n",
    "  return (input_id,mask,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_col = 'extract_with_tags'\n",
    "# sent_col = 'extract_no_tags'\n",
    "target_col = 'label_str'\n",
    "# target_col = 'propaganda'\n",
    "\n",
    "train_data = CustomPropagandaDataset_vanilla(train_df,sent_col, target_col)\n",
    "val_data = CustomPropagandaDataset_vanilla(val_df,sent_col, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=torch.utils.data.DataLoader(train_data,batch_size=50,shuffle=True)\n",
    "val_dataloader=torch.utils.data.DataLoader(val_data,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self,dropout=0.5,num_classes=2):\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert=BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.linear=nn.Linear(768,num_classes)\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def forward(self,input_id,mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids=input_id,attention_mask=mask,return_dict=False)\n",
    "        dropout_output=self.dropout(pooled_output)\n",
    "        linear_output=self.linear(dropout_output)\n",
    "        final_layer=self.relu(linear_output)\n",
    "\n",
    "        return final_layer\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wills\n",
    "epochs = 3\n",
    "lr = 5e-6\n",
    "batch_size=50\n",
    "max_len=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "\n",
    "\n",
    "model=BertClassifier(num_classes=9).to(device)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "train_acc_list = []\n",
    "train_loss_list = []\n",
    "val_acc_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "best_val_acc = 0\n",
    "best_epoch = 0\n",
    "best_model_state = None\n",
    "\n",
    "model_id = str(uuid.uuid4())\n",
    "\n",
    "\n",
    "for epoch_num in range(epochs):\n",
    "        total_acc_train=0\n",
    "        total_loss_train=0\n",
    "        model.train()\n",
    "        for train_input,train_label in tqdm(train_dataloader):\n",
    "\n",
    "            input_id,mask, train_label=prepare_inputs(train_input,train_label,device)\n",
    "\n",
    "            output_1=model(input_id,mask)\n",
    "\n",
    "            batch_loss_1=criterion(output_1,train_label.long())\n",
    "            total_loss_train +=batch_loss_1.item()\n",
    "\n",
    "            acc=(output_1.argmax(dim=1)==train_label).sum().item()\n",
    "            total_acc_train+=acc\n",
    "\n",
    "            model.zero_grad()\n",
    "            batch_loss_1.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_acc_val=0\n",
    "        total_loss_val=0\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_input,val_label in val_dataloader:\n",
    "\n",
    "                input_id,mask, val_label=prepare_inputs(val_input,val_label,device)\n",
    "\n",
    "                output_2= model(input_id,mask)\n",
    "\n",
    "                # for scoring\n",
    "                predicted = output_2.argmax(dim=1)\n",
    "                y_true.extend(val_label.cpu().numpy())\n",
    "                y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "                batch_loss_2=criterion(output_2,val_label.long())\n",
    "\n",
    "                total_loss_val+=batch_loss_2.item()\n",
    "\n",
    "                acc=(output_2.argmax(dim=1)==val_label).sum().item()\n",
    "                total_acc_val+=acc\n",
    "            train_acc = total_acc_train / len(train_data)\n",
    "\n",
    "        train_loss = total_loss_train / len(train_data)\n",
    "        val_acc = total_acc_val / len(val_data)\n",
    "        val_loss = total_loss_val / len(val_data)\n",
    "\n",
    "        train_acc_list.append(train_acc)\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_acc_list.append(val_acc)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "        print(f'Epochs: {epoch_num+1} | Train Loss: {total_loss_train / len(train_data):.3f} | Train Accuracy: {total_acc_train/len(train_data):.3f}')\n",
    "        print(f'Val loss: {total_loss_val/len(val_data):.3f} | Val Accuracy: {total_acc_val / len(val_data):.3f}')\n",
    "        if val_acc > best_val_acc:\n",
    "          best_epoch = epoch_num\n",
    "          y_true_best = y_true.copy()\n",
    "          y_pred_best = y_pred.copy()\n",
    "          best_val_acc = val_acc\n",
    "          best_model_state = model.state_dict()\n",
    "\n",
    "        if epoch_num == epochs-1:\n",
    "            print(f'______{model_id}______')\n",
    "            print(f'LR: {lr} FINAL ACC = {total_acc_val / len(val_data):.3f}')\n",
    "            print(f'LR: {lr} BEST ACC = {best_val_acc:.3f}')\n",
    "            print('____________')\n",
    "\n",
    "\n",
    "# Plot the accuracy and loss curves over epochs\n",
    "epochs_range = range(1, epochs+1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, train_acc_list, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc_list, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Accuracy Curves')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, train_loss_list, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss_list, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss Curves')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# # Create a dictionary to store the results, hyperparameters, and model ID\n",
    "# results_dict = {\n",
    "#     'model_id': model_id,\n",
    "#     'train_accuracy': train_acc_list,\n",
    "#     'train_loss': train_loss_list,\n",
    "#     'val_accuracy': val_acc_list,\n",
    "#     'val_loss': val_loss_list,\n",
    "#     'hyperparameters': {\n",
    "#         'learning_rate': lr,\n",
    "#         'num_epochs': epochs,\n",
    "#         'batch_size': batch_size,\n",
    "#         'max_len': max_len\n",
    "#     },\n",
    "#     'results': {\n",
    "#         \"last_acc\": val_acc_list[-1],\n",
    "#         'best_acc': best_val_acc,\n",
    "#         'confusion_matrix': cm.tolist(),\n",
    "#         'classification_report': report\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Save the results dictionary as a JSON file with the model ID\n",
    "# results_filename = f'results_{model_id}.json'\n",
    "# with open(results_filename, 'w') as f:\n",
    "#     json.dump(results_dict, f, indent=4)\n",
    "\n",
    "# # Save the best model state with the model ID\n",
    "# model_filename = f'best_model_{model_id}.pth'\n",
    "# torch.save(best_model_state, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis of best performing model\n",
    "\n",
    "cm = confusion_matrix(y_true_best, y_pred_best)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "classes = ['Class 0', 'Class 1']  # Replace with your class labels\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute precision, recall, F1-score, and other metrics for best one\n",
    "report = classification_report(y_true, y_pred, target_names=classes)\n",
    "print('Classification Report:')\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
