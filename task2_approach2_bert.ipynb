{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdWHfLCaVsr7"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from utils import *\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_str = 'IM JUST A STOOPID LIL TEST'"
      ],
      "metadata": {
        "id": "n9ud_UnbV2oO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVGC1qIDVsr9"
      },
      "outputs": [],
      "source": [
        "epochs = 3\n",
        "lr = 0.1\n",
        "n_labels = ................?????????\n",
        "manual_loss= False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXNJDNOBVssA"
      },
      "outputs": [],
      "source": [
        "include_dev=False\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "batch_size_train = 8\n",
        "batch_size_test = 8\n",
        "batch_size_dev = 8\n",
        "\n",
        "if include_dev:\n",
        "    train_df, val_df, test_df = get_processed_data(dev=True)\n",
        "\n",
        "    train_df= get_cols_for_bert(train_df, 'snip')\n",
        "    val_df= get_cols_for_bert(val_df, 'snip')\n",
        "    test_df= get_cols_for_bert(test_df, 'snip')\n",
        "\n",
        "    train_input_embeddings_labelled = format_and_tokenise_from_df(train_df, tokenizer, task='snip')\n",
        "    val_input_embeddings_labelled = format_and_tokenise_from_df(val_df, tokenizer, task='snip')\n",
        "    test_input_embeddings_labelled = format_and_tokenise_from_df(test_df, tokenizer, task='snip')\n",
        "\n",
        "    train_dataset = CustomPropagandaDataset(train_input_embeddings_labelled)\n",
        "    test_dataset = CustomPropagandaDataset(test_input_embeddings_labelled)\n",
        "    val_dataset = CustomPropagandaDataset(val_input_embeddings_labelled)\n",
        "\n",
        "\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size_test, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size_dev, shuffle=True)\n",
        "\n",
        "\n",
        "else:\n",
        "    train_df, val_df = get_processed_data(dev=False)\n",
        "\n",
        "    train_df= get_cols_for_bert(train_df, 'snip')\n",
        "    val_df= get_cols_for_bert(val_df, 'snip')\n",
        "\n",
        "    train_input_embeddings_labelled = format_and_tokenise_from_df(train_df, tokenizer, task='snip')\n",
        "    val_input_embeddings_labelled = format_and_tokenise_from_df(val_df, tokenizer, task='snip')\n",
        "\n",
        "    train_dataset = CustomPropagandaDataset(train_input_embeddings_labelled)\n",
        "    val_dataset = CustomPropagandaDataset(val_input_embeddings_labelled)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size_dev, shuffle=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSq4a21UVssB"
      },
      "outputs": [],
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=n_labels)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "\n",
        "train_losses = []\n",
        "train_accuracy = []\n",
        "val_losses = []\n",
        "val_accuracy = []\n",
        "\n",
        "model.to(device)\n",
        "for epoch in range(epochs):\n",
        "  train_running_losses = []\n",
        "  train_total = 0\n",
        "  train_correct = 0\n",
        "  model.train()\n",
        "  for batch in tqdm(train_dataloader):\n",
        "\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "    outputs = model(**batch)\n",
        "\n",
        "    # IN BUILT LOSS\n",
        "\n",
        "    if manual_loss:\n",
        "      loss = criterion(outputs.logits, batch['labels'])\n",
        "    else:\n",
        "      loss = outputs[0]\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    _, indices = torch.max(outputs['logits'], dim=1)\n",
        "    predicted_labels = indices.float()\n",
        "\n",
        "    train_total += batch['labels'].size(0)\n",
        "    train_correct += (predicted_labels == batch['labels']).sum().item()\n",
        "    train_running_losses.append(loss.item())\n",
        "\n",
        "  train_losses.append(sum(train_running_losses)/len(train_running_losses))\n",
        "  train_accuracy.append(train_correct/train_total)\n",
        "\n",
        "  print(f'TRAIN: Epoch [{epoch}/{epochs}] Loss: {sum(train_running_losses)/len(train_running_losses)} Acc: {train_correct/train_total}')\n",
        "\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    val_running_losses = []\n",
        "    val_total = 0\n",
        "    val_correct = 0\n",
        "    for batch in tqdm(val_dataloader):\n",
        "      batch = {k: v.to(device) for k, v in batch.items()}\n",
        "      outputs = model(**batch)\n",
        "      loss = outputs[0]\n",
        "      # Convert outputs to predicted labels (0 or 1 based on threshold 0.5)\n",
        "      _, indices = torch.max(outputs['logits'], dim=1)\n",
        "      predicted_labels = indices.float()\n",
        "\n",
        "      # Calculate accuracy\n",
        "      val_total += batch['labels'].size(0)\n",
        "      val_correct += (predicted_labels == batch['labels']).sum().item()\n",
        "      val_running_losses.append(loss.item())\n",
        "\n",
        "  val_losses.append(sum(val_running_losses)/len(val_running_losses))\n",
        "  val_accuracy.append(val_correct/val_total)\n",
        "\n",
        "  print(f'VAL: Epoch [{epoch + 1}/{epochs}] Loss: {sum(val_running_losses)/len(val_running_losses)} Acc: {val_correct/val_total}')\n",
        "\n",
        "if include_dev:\n",
        "  print('TESTING...')\n",
        "  test_losses = []\n",
        "  test_accuracy = []\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      test_running_losses = []\n",
        "      test_total = 0\n",
        "      test_correct = 0\n",
        "      for batch in test_dataloader:\n",
        "          batch = {k: v.to(device) for k, v in batch.items()}\n",
        "          outputs = model(**batch)\n",
        "          loss = outputs[0]\n",
        "          # Convert outputs to predicted labels (0 or 1 based on threshold 0.5)\n",
        "          _, indices = torch.max(outputs['logits'], dim=1)\n",
        "          predicted_labels = indices.float()\n",
        "\n",
        "          # Calculate accuracy\n",
        "          test_total += batch['labels'].size(0)\n",
        "          test_correct += (predicted_labels == batch['labels']).sum().item()\n",
        "          test_running_losses.append(loss.item())\n",
        "\n",
        "      test_losses.append(sum(test_running_losses)/len(test_running_losses))\n",
        "      test_accuracy.append(test_correct/test_total)\n",
        "  print(f'TEST: Epoch [{epoch + 1}/{epochs}] Loss: {sum(test_running_losses)/len(test_running_losses)} Acc: {test_correct/test_total}')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}