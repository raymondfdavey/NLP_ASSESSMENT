{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rfd/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2024-05-08 14:29:30.332476: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_original, val_df_original = get_processed_data(dev=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2560, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_original.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPropagandaDataset_vanilla(Dataset):\n",
    "    def __init__(self,df,dataset='prop'):\n",
    "        \n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "        \n",
    "        if dataset == 'prop':\n",
    "            target_col = 'propaganda'\n",
    "            text_col = 'original_sentence_no_tags'\n",
    "            \n",
    "            self.labels=torch.tensor([label for label in df[target_col]])\n",
    "\n",
    "            \n",
    "        if dataset == 'snip':\n",
    "            label_to_id = {'flag_waving': 0, 'exaggeration,minimisation': 1, 'causal_oversimplification': 2, 'name_calling,labeling': 3, 'repetition': 4, 'doubt': 5, 'not_propaganda': 6, 'loaded_language': 7, 'appeal_to_fear_prejudice': 8}\n",
    "            \n",
    "            target_col = 'snippet_label'\n",
    "            text_col = 'snippet_original'\n",
    "            self.labels=torch.tensor([label_to_id[label] for label in df[target_col]])\n",
    "            \n",
    "        self.texts=[tokenizer(text,padding='max_length',max_length=200,truncation=True,return_tensors=\"pt\") for text in df[text_col]]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self,idx):\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self,idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        batch_texts=self.get_batch_texts(idx)\n",
    "        batch_y=self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts,batch_y\n",
    "\n",
    "\n",
    "def prepare_inputs(input1,label,device):\n",
    "  label=label.to(device)\n",
    "  mask=input1['attention_mask'].to(device)\n",
    "  input_id=input1['input_ids'].squeeze(1).to(device)\n",
    "  return (input_id,mask,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomPropagandaDataset_vanilla(train_df_original)\n",
    "val_data = CustomPropagandaDataset_vanilla(val_df_original)\n",
    "\n",
    "train_dataloader=torch.utils.data.DataLoader(train_data,batch_size=64,shuffle=True)\n",
    "val_dataloader=torch.utils.data.DataLoader(val_data,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataloader:\n",
    "    print(len(i[1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
