{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: Sentence Completion Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will load the language_model class (developed last week) and train it using the files in the training directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2  #this means that language_model will be reloaded when you run this cell - this is important if you change the language_model class!\n",
    "import os\n",
    "from lab5resources.language_model import * ## import language model from previous lab\n",
    "parentdir=\"/Users/juliewe/Dropbox/teaching/AdvancedNLP/2024/week4/lab4/lab4resources/sentence-completion\" #you may need to update this \n",
    "\n",
    "trainingdir=os.path.join(parentdir,\"Holmes_Training_Data\")\n",
    "training,testing=get_training_testing(trainingdir)\n",
    "MAX_FILES=20   #use a small number here whilst developing your solutions\n",
    "mylm=language_model(trainingdir=trainingdir,files=training[:MAX_FILES],adjust_unknowns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the most frequent words in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=sorted(mylm.unigram.items(),key=lambda x:x[1],reverse =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the vocabulary?  What kind of words are low frequency?  What kind of words are mid-frequency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topvocab=vocab[:9500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topvocab[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you can:\n",
    "* look up bigram probabilities\n",
    "* generatate a sentence according to the model\n",
    "* calculate the perplexity of a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets load in and have a look at the sentence completion challenge questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, csv\n",
    "questions=os.path.join(parentdir,\"testing_data.csv\")\n",
    "answers=os.path.join(parentdir,\"test_answer.csv\")\n",
    "\n",
    "with open(questions) as instream:\n",
    "    csvreader=csv.reader(instream)\n",
    "    lines=list(csvreader)\n",
    "qs_df=pd.DataFrame(lines[1:],columns=lines[0])\n",
    "qs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to be able to tokenize questions so that the gaps can be located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize as tokenize\n",
    "\n",
    "tokens=[tokenize(q) for q in qs_df['question']]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the context of the blank: looking at the preceding words (number given in window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_left_context(sent_tokens,window,target=\"_____\"):\n",
    "    found=-1\n",
    "    for i,token in enumerate(sent_tokens):\n",
    "        if token==target:\n",
    "            found=i\n",
    "            break \n",
    "            \n",
    "    if found>-1:\n",
    "        return sent_tokens[i-window:i]\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "\n",
    "qs_df['tokens']=qs_df['question'].map(tokenize)\n",
    "qs_df['left_context']=qs_df['tokens'].map(lambda x: get_left_context(x,2))\n",
    "qs_df.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Building and evaluating an SCC system\n",
    "1. always predict the same answer (e.g., \"a\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lab3resources.scc import *\n",
    "### you can import this the above line but I have included the code here to make it easier to inspect it\n",
    "\n",
    "class question:\n",
    "    \n",
    "    def __init__(self,aline):\n",
    "        self.fields=aline\n",
    "    \n",
    "    def get_field(self,field):\n",
    "        return self.fields[question.colnames[field]]\n",
    "    \n",
    "    def add_answer(self,fields):\n",
    "        self.answer=fields[1]\n",
    "   \n",
    "    def chooseA(self):\n",
    "        return(\"a\")\n",
    "    \n",
    "    def predict(self,method=\"chooseA\"):\n",
    "        #eventually there will be lots of methods to choose from\n",
    "        if method==\"chooseA\":\n",
    "            return self.chooseA()\n",
    "        \n",
    "    def predict_and_score(self,method=\"chooseA\"):\n",
    "        \n",
    "        #compare prediction according to method with the correct answer\n",
    "        #return 1 or 0 accordingly\n",
    "        prediction=self.predict(method=method)\n",
    "        if prediction ==self.answer:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "class scc_reader:\n",
    "    \n",
    "    def __init__(self,qs=questions,ans=answers):\n",
    "        self.qs=qs\n",
    "        self.ans=ans\n",
    "        self.read_files()\n",
    "        \n",
    "    def read_files(self):\n",
    "        \n",
    "        #read in the question file\n",
    "        with open(self.qs) as instream:\n",
    "            csvreader=csv.reader(instream)\n",
    "            qlines=list(csvreader)\n",
    "        \n",
    "        #store the column names as a reverse index so they can be used to reference parts of the question\n",
    "        question.colnames={item:i for i,item in enumerate(qlines[0])}\n",
    "        \n",
    "        #create a question instance for each line of the file (other than heading line)\n",
    "        self.questions=[question(qline) for qline in qlines[1:]]\n",
    "        \n",
    "        #read in the answer file\n",
    "        with open(self.ans) as instream:\n",
    "            csvreader=csv.reader(instream)\n",
    "            alines=list(csvreader)\n",
    "            \n",
    "        #add answers to questions so predictions can be checked    \n",
    "        for q,aline in zip(self.questions,alines[1:]):\n",
    "            q.add_answer(aline)\n",
    "        \n",
    "    def get_field(self,field):\n",
    "        return [q.get_field(field) for q in self.questions] \n",
    "    \n",
    "    def predict(self,method=\"chooseA\"):\n",
    "        return [q.predict(method=method) for q in self.questions]\n",
    "    \n",
    "    def predict_and_score(self,method=\"chooseA\"):\n",
    "        scores=[q.predict_and_score(method=method) for q in self.questions]\n",
    "        return sum(scores)/len(scores)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCC = scc_reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCC.get_field(\"b)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCC.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCC.predict_and_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a random choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class question(question):\n",
    "    \n",
    "    #you wouldn't normally have a class inherit from itself like this\n",
    "    #but it is quite a neat way in jupyter notebooks to extend pre-existing classes\n",
    "    #you could alternatively redefine the class (copying all of the pre-existing class)\n",
    "\n",
    "    def chooserandom(self):\n",
    "        choices=[\"a\",\"b\",\"c\",\"d\",\"e\"]\n",
    "        return np.random.choice(choices)\n",
    "    def predict(self,method=\"chooseA\"):\n",
    "        if method==\"chooseA\":\n",
    "            return self.chooseA()\n",
    "        elif method==\"random\":\n",
    "            return self.chooserandom()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCC=scc_reader()\n",
    "SCC.predict_and_score(method=\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the language model\n",
    "using unigram probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class question(question):\n",
    "    #you wouldn't normally have a class inherit from itself like this\n",
    "    #but it is quite a neat way in jupyter notebooks to extend pre-existing classes\n",
    "    #you could alternatively redefine the class (copying all of the pre-existing class)\n",
    "\n",
    "    def chooseunigram(self,lm):\n",
    "        choices=[\"a\",\"b\",\"c\",\"d\",\"e\"]      \n",
    "        probs=[lm.unigram.get(self.get_field(ch+\")\"),0) for ch in choices]\n",
    "        maxprob=max(probs)\n",
    "        bestchoices=[ch for ch,prob in zip(choices,probs) if prob == maxprob]\n",
    "        #if len(bestchoices)>1:\n",
    "        #    print(\"Randomly choosing from {}\".format(len(bestchoices)))\n",
    "        return np.random.choice(bestchoices)\n",
    "    \n",
    "    def predict(self,method=\"chooseA\",lm=mylm):\n",
    "        if method==\"chooseA\":\n",
    "            return self.chooseA()\n",
    "        elif method==\"random\":\n",
    "            return self.chooserandom()\n",
    "        elif method==\"unigram\":\n",
    "            return self.chooseunigram(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCC=scc_reader()\n",
    "SCC.predict_and_score(method=\"unigram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Context\n",
    "looking up context and bigram probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class question(question):\n",
    "    #you wouldn't normally have a class inherit from itself like this\n",
    "    #but it is quite a neat way in jupyter notebooks to extend pre-existing classes\n",
    "    #you could alternatively redefine the class (copying all of the pre-existing class)\n",
    "\n",
    "    \n",
    "    def get_tokens(self):\n",
    "        return [\"__START\"]+tokenize(self.fields[question.colnames[\"question\"]])+[\"__END\"]\n",
    "    \n",
    "    def get_left_context(self,window=1,target=\"_____\"):\n",
    "        found=-1\n",
    "        sent_tokens=self.get_tokens()\n",
    "        for i,token in enumerate(sent_tokens):\n",
    "            if token==target:\n",
    "                found=i\n",
    "                break  \n",
    "            \n",
    "        if found>-1:\n",
    "            return sent_tokens[i-window:i]\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    def choose(self,lm,method=\"bigram\",choices=[]):\n",
    "        if choices==[]:\n",
    "            choices=[\"a\",\"b\",\"c\",\"d\",\"e\"]\n",
    "        context=self.get_left_context(window=1)\n",
    "        probs=[lm.get_prob(self.get_field(ch+\")\"),context,methodparams={\"method\":method}) for ch in choices]\n",
    "        maxprob=max(probs)\n",
    "        bestchoices=[ch for ch,prob in zip(choices,probs) if prob == maxprob]\n",
    "        #if len(bestchoices)>1:\n",
    "        #    print(\"Randomly choosing from {}\".format(len(bestchoices)))\n",
    "        return np.random.choice(bestchoices)\n",
    "    \n",
    "    def predict(self,method=\"chooseA\",model=mylm):\n",
    "        if method==\"chooseA\":\n",
    "            return self.chooseA()\n",
    "        elif method==\"random\":\n",
    "            return self.chooserandom()\n",
    "        else:\n",
    "            return self.choose(mylm,method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCC=scc_reader()\n",
    "SCC.predict_and_score(method=\"bigram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_df[\"bigram_pred\"]=SCC.predict(method=\"bigram\")\n",
    "qs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_df[\"unigram_pred\"]=SCC.predict(method=\"unigram\")\n",
    "qs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylm.unigram[\"theological\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylm.get_prob(\"theological\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylm.bigram[\",\"][\"theological\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylm.get_prob(\"theological\",context=[\",\"],methodparams={\"method\":\"bigram\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylm.unigram[\"residing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylm.get_prob(\"residing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylm.get_prob(\"residing\",context=[\"are\"],methodparams={\"method\":\"bigram\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class question(question):\n",
    "    #you wouldn't normally have a class inherit from itself like this\n",
    "    #but it is quite a neat way in jupyter notebooks to extend pre-existing classes\n",
    "    #you could alternatively redefine the class (copying all of the pre-existing class)\n",
    "\n",
    "    def get_right_context(self,window=1,target=\"_____\"):\n",
    "        found=-1\n",
    "        sent_tokens=self.get_tokens()\n",
    "        for i,token in enumerate(sent_tokens):\n",
    "            if token==target:\n",
    "                found=i\n",
    "                break  \n",
    "          \n",
    "        if found>-1:\n",
    "            \n",
    "            return sent_tokens[found+1:found+window+1]\n",
    "           \n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    def choose(self,lm,method=\"bigram_left\",choices=[]):\n",
    "        if choices==[]:\n",
    "            choices=[\"a\",\"b\",\"c\",\"d\",\"e\"]\n",
    "        if method==\"bigram_right\":\n",
    "            context=self.get_right_context(window=1)\n",
    "            probs=[lm.get_prob(context[0],[self.get_field(ch+\")\")],methodparams={\"method\":method.split(\"_\")[0]}) for ch in choices]\n",
    "        else:\n",
    "            context=self.get_left_context(window=1)\n",
    "            probs=[lm.get_prob(self.get_field(ch+\")\"),context,methodparams={\"method\":method.split(\"_\")[0]}) for ch in choices]\n",
    "        maxprob=max(probs)\n",
    "        bestchoices=[ch for ch,prob in zip(choices,probs) if prob == maxprob]\n",
    "        #if len(bestchoices)>1:\n",
    "        #    print(\"Randomly choosing from {}\".format(len(bestchoices)))\n",
    "        return np.random.choice(bestchoices)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCC=scc_reader()\n",
    "SCC.predict_and_score(method=\"bigram_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class question(question):\n",
    "    #you wouldn't normally have a class inherit from itself like this\n",
    "    #but it is quite a neat way in jupyter notebooks to extend pre-existing classes\n",
    "    #you could alternatively redefine the class (copying all of the pre-existing class)\n",
    "\n",
    "   \n",
    "    \n",
    "    def choose(self,lm,method=\"bigram\",choices=[]):\n",
    "        if choices==[]:\n",
    "            choices=[\"a\",\"b\",\"c\",\"d\",\"e\"]\n",
    "        if method==\"bigram\":\n",
    "            rc=self.get_right_context(window=1)\n",
    "            lc=self.get_left_context(window=1)\n",
    "            probs=[lm.get_prob(rc[0],[self.get_field(ch+\")\")],methodparams={\"method\":method.split(\"_\")[0]})*lm.get_prob(self.get_field(ch+\")\"),lc,methodparams={\"method\":method.split(\"_\")[0]}) for ch in choices]\n",
    "        elif method==\"bigram_right\":\n",
    "            context=self.get_right_context(window=1)\n",
    "            probs=[lm.get_prob(context[0],[self.get_field(ch+\")\")],methodparams={\"method\":method.split(\"_\")[0]}) for ch in choices]\n",
    "        else:\n",
    "            #this covers bigram_left and unigram\n",
    "            context=self.get_left_context(window=1)\n",
    "            probs=[lm.get_prob(self.get_field(ch+\")\"),context,methodparams={\"method\":method.split(\"_\")[0]}) for ch in choices]\n",
    "        maxprob=max(probs)\n",
    "        bestchoices=[ch for ch,prob in zip(choices,probs) if prob == maxprob]\n",
    "        #if len(bestchoices)>1:\n",
    "        #    print(\"Randomly choosing from {}\".format(len(bestchoices)))\n",
    "        return np.random.choice(bestchoices)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCC=scc_reader()\n",
    "SCC.predict_and_score(method=\"bigram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backing off to unigram probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class question(question):\n",
    "    #you wouldn't normally have a class inherit from itself like this\n",
    "    #but it is quite a neat way in jupyter notebooks to extend pre-existing classes\n",
    "    #you could alternatively redefine the class (copying all of the pre-existing class)\n",
    "\n",
    "    \n",
    "    def choose_backoff(self,lm,methods=['bigram','unigram'],choices=[\"a\",\"b\",\"c\",\"d\",\"e\"]):\n",
    "        context=self.get_left_context(window=1)\n",
    "        probs=[lm.get_prob(self.get_field(ch+\")\"),context,methodparams={\"method\":methods[0]}) for ch in choices]\n",
    "        maxprob=max(probs)\n",
    "        bestchoices=[ch for ch,prob in zip(choices,probs) if prob == maxprob]\n",
    "        if len(bestchoices)>1:\n",
    "            print(\"Backing off on {}\".format(len(bestchoices)))\n",
    "        return self.choose(lm,choices=bestchoices,method=methods[1])\n",
    "    \n",
    "    def predict(self,method=\"chooseA\",model=mylm):\n",
    "        if method==\"chooseA\":\n",
    "            return self.chooseA()\n",
    "        elif method==\"random\":\n",
    "            return self.chooserandom()\n",
    "        elif method==\"bigram_backoff\":\n",
    "            return self.choose_backoff(mylm,methods=[\"bigram\",\"unigram\"])\n",
    "        else:\n",
    "            return self.choose(mylm,method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCC=scc_reader()\n",
    "SCC.predict_and_score(method=\"bigram_backoff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backing off might not change the decision (the correct answer may not be in the bestchoices given back by the bigram model)\n",
    "\n",
    "Investigate: \n",
    "* the effect of the amount of training data on each of the strategies\n",
    "* plot on a graph - should see a cross-over (unigram than bigram for small training data but bigram better than unigram for large training data)\n",
    "\n",
    "Extend:\n",
    "* trigram model\n",
    "* incorporation of distributional similarity / word2vec vectors\n",
    "* RNNLM ...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
