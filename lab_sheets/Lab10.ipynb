{"cells":[{"cell_type":"markdown","id":"fc3cfa3e","metadata":{"id":"fc3cfa3e"},"source":["# Lab 10: Transfer Learning with BERT\n","\n","In this lab we are going to be looking at fine-tuning a BERT model to carry out a sequence classification task.\n","\n","We are going to load in some text from a small number of books in the Gutenberg corpus and see if we can train a classifier to classify which book a piece of text is from\n","\n","First lets pull up all of the filenames available."]},{"cell_type":"code","execution_count":1,"id":"p2z_2FOZCmSg","metadata":{"executionInfo":{"elapsed":1869,"status":"ok","timestamp":1713779338284,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"p2z_2FOZCmSg"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":2,"id":"mK94ndl-3SZq","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86943,"status":"ok","timestamp":1713779425225,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"mK94ndl-3SZq","outputId":"fa342f0a-59ed-43c5-d988-6ad5bfe887fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","IN COLAB:  True\n"]}],"source":["try :\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  IN_COLAB = True\n","except:\n","  IN_COLAB = False\n","print('IN COLAB: ', IN_COLAB)"]},{"cell_type":"code","execution_count":3,"id":"95649de7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8673,"status":"ok","timestamp":1713779433895,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"95649de7","outputId":"9e059fbd-3f53-4600-bfb6-6914c8b8aed2"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 525 files in the training directory: /content/drive/MyDrive/MSc/modules/2.2/2.2-Language P-2/week4-NN_bigram_unigram/lab4resources_full/sentence-completion/Holmes_Training_Data\n"]}],"source":["import os,random,math\n","if IN_COLAB:\n","  TRAINING_DIR=\"/content/drive/MyDrive/MSc/modules/2.2/2.2-Language P-2/week4-NN_bigram_unigram/lab4resources_full/sentence-completion/Holmes_Training_Data\" #this needs to be the parent directory for the training corpus\n","else:\n","  TRAINING_DIR=\"../../../week4/lab4/lab4resources/sentence-completion/Holmes_Training_Data\" #this needs to be the parent directory for the training corpus\n","\n","filenames=os.listdir(TRAINING_DIR)\n","n=len(filenames)\n","print(\"There are {} files in the training directory: {}\".format(n,TRAINING_DIR))\n","\n","#print(filenames)"]},{"cell_type":"markdown","id":"5a2c2c4d","metadata":{"id":"5a2c2c4d"},"source":["We are going to create a Book class to store the text from a class and do some very basic pre-processing.  We need to\n","* load in the text line-by-line\n","* get rid of header lines (the stuff in the file before the line which starts \\*END\\*THE SMALL PRINT!)\n","* make chunks of text which are longer than 1 line.  These should be easier to classify.  We will try to get sentences - but some chunks may contain multiple sentences.  We are not going to worry about this here.\n","* return some labelled data split randomly between training and testing"]},{"cell_type":"code","execution_count":4,"id":"f22eabd7","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1713779433895,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"f22eabd7"},"outputs":[],"source":["class Book():\n","\n","    header_end=\"*END*THE SMALL PRINT!\"\n","    seed=53\n","\n","    def __init__(self, filename, training_dir, label=\"\"):\n","        self.TRAINING_DIR = training_dir\n","        self.filename=filename\n","        self.loadfile()\n","        self.make_chunks()\n","        if label==\"\":\n","            self.label=self.filename\n","        else:\n","            self.label=label\n","\n","    def loadfile(self):\n","        filepath=os.path.join(self.TRAINING_DIR,self.filename)\n","        self.lines=[]\n","        beyond_header=False\n","        try:\n","            with open(filepath) as instream:\n","                for line in instream:\n","                    line=line.rstrip()\n","\n","                    if len(line)>0 and beyond_header:\n","                        self.lines.append(line)\n","                    if line.startswith(Book.header_end):\n","                        beyond_header=True\n","        except UnicodeDecodeError:\n","            print(f\"UnicodeDecodeError processing {filepath}\")\n","\n","    def length(self):\n","        return len(self.chunks)\n","\n","    def head(self,n=10):\n","        return self.chunks[:n]\n","\n","    def make_chunks(self):\n","        self.chunks=[]\n","\n","        current=\"\"\n","        for line in self.lines:\n","            current+=line+\" \"\n","            if line.endswith(\".\"):\n","                self.chunks.append(current.rstrip())\n","                current=\"\"\n","\n","    def get_labelled_data(self,split=0.8):\n","        labelled_data=[(chunk,self.label) for chunk in self.chunks]\n","        random.seed(Book.seed)\n","        random.shuffle(labelled_data)\n","        index=int(self.length()*split)\n","        return (labelled_data[:index],labelled_data[index:])\n"]},{"cell_type":"markdown","id":"03451e9f","metadata":{"id":"03451e9f"},"source":["### Exercise 1\n","- Create an instance of a Book() and store it in the variable `emma`.  The filename is `EMMA10.TXT` and the label should be `Emma`\n","- Check the number of sentences = 2028 and have a look at the first 10 sentence\n","- Repeat to create `ivanhoe` to store the text from `IVNHO12.TXT` with the label `Ivanhoe`.  \n","- The number of sentences in `ivanhoe` should be 1743"]},{"cell_type":"code","execution_count":5,"id":"9356eba3","metadata":{"executionInfo":{"elapsed":495,"status":"ok","timestamp":1713779434380,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"9356eba3"},"outputs":[],"source":["emma = Book('EMMA10.TXT', TRAINING_DIR, 'Emma')\n","emma.loadfile()"]},{"cell_type":"code","execution_count":6,"id":"f8b471c0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1713779434380,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"f8b471c0","outputId":"91971633-d4e6-44d4-b5eb-5cab292f9959"},"outputs":[{"data":{"text/plain":["2028"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["emma.length()"]},{"cell_type":"code","execution_count":7,"id":"ae3cb496","metadata":{"executionInfo":{"elapsed":1216,"status":"ok","timestamp":1713779435595,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"ae3cb496"},"outputs":[],"source":["ivanhoe = Book('IVNHO12.TXT', TRAINING_DIR, 'Ivanhoe')\n","ivanhoe.loadfile()"]},{"cell_type":"code","execution_count":8,"id":"cf1e4ba7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1713779436151,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"cf1e4ba7","outputId":"b42c636b-3e1d-4960-f076-b950e10cdc78"},"outputs":[{"data":{"text/plain":["1743"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["ivanhoe.length()"]},{"cell_type":"markdown","id":"c7f6b58e","metadata":{"id":"c7f6b58e"},"source":["### Exercise 2\n","- Use the `get_labelled_data()` method to get a training and testing portion from each book (split = 80%).  \n","- Create 2 pandas dataframes\n","    - 1 dataframe called `training_df` with all of the training data (from both books)\n","    - 1 dataframe called  `testing_df`  with all of the test data (from both books).  \n","    - The columns of both dataframes should be `text` and `label`"]},{"cell_type":"code","execution_count":9,"id":"f509139a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1713779436151,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"f509139a","outputId":"d6bf4ad6-31af-49ed-e468-a6b958f655bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["1394\n","349\n","1622\n","406\n"]}],"source":["iv_train, iv_test = ivanhoe.get_labelled_data()\n","em_train, em_test = emma.get_labelled_data()\n","\n","print(len(iv_train))\n","print(len(iv_test))\n","print(len(em_train))\n","print(len(em_test))\n"]},{"cell_type":"code","execution_count":10,"id":"c24455cd","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1713779436151,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"c24455cd"},"outputs":[],"source":["train = iv_train + em_train\n","test = iv_test + em_test"]},{"cell_type":"code","execution_count":11,"id":"9cf4cf62","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1713779436151,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"9cf4cf62","outputId":"14d639a0-05d0-44b2-a4cb-169e95c54d39"},"outputs":[{"name":"stdout","output_type":"stream","text":["3016\n","755\n"]}],"source":["print(len(train))\n","print(len(test))"]},{"cell_type":"code","execution_count":12,"id":"86ebc4a2","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1713779436151,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"86ebc4a2"},"outputs":[],"source":["train_X, train_y = zip(*train)\n","test_X, test_y = zip(*test)"]},{"cell_type":"code","execution_count":13,"id":"dff8e3c7","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1713779436151,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"dff8e3c7"},"outputs":[],"source":["training_df = pd.DataFrame({'text': train_X, 'label': train_y })\n","testing_df = pd.DataFrame({'text': test_X, 'label': test_y })"]},{"cell_type":"markdown","id":"d66426b3","metadata":{"id":"d66426b3"},"source":["## Finetuning BERT to tell the difference between sentences from each book\n","\n","Now we are going to look at building a classifier on top of BERT.  The first thing we need to do is map the informative label names we have (`Emma` and `Ivanhoe`) to integers which will be used by BERT.  In this simple case, we could just create a dictionary manually.  However, the code below will make a sorted list (without duplicates) of all of the labelnames in the two dataframes and then generate a dictionary which maps each label name to an integer.\n"]},{"cell_type":"code","execution_count":14,"id":"94dcd9dd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1713779436152,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"94dcd9dd","outputId":"14706a18-8eae-4130-eb5a-f41c267a5178"},"outputs":[{"data":{"text/plain":["{'Emma': 0, 'Ivanhoe': 1}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["#first we need a map for the labels\n","\n","#make a list of all of the unique labels in the training and testing dataframes\n","#sorting it means that it will also be in the same order (alphabetical) rather than depending on order in the training / testing data\n","labellist=sorted(list(set(training_df['label'].unique()).union(set(testing_df['label'].unique()))))\n","\n","labels={label:i for i,label in enumerate(labellist)}\n","labels"]},{"cell_type":"markdown","id":"e72e7236","metadata":{"id":"e72e7236"},"source":["### Exercise 3\n","Write some code to create a reverse index for the labels which maps the numbers back to the more informative strings\n","\n","This should result in something which looks as follows:\n","\n","```\n","reverse_index={0:'Emma',1:'Ivanhoe'}\n","```\n","\n","But obviously, you should create it automatically from the labels dictionary rather than typing it in!"]},{"cell_type":"code","execution_count":15,"id":"6f39dbb3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1713779436152,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"6f39dbb3","outputId":"d19c9290-c0ec-4b05-b76b-8867d531229d"},"outputs":[{"data":{"text/plain":["{0: 'Emma', 1: 'Ivanhoe'}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["reverse_index = {num_label: st_label for (st_label, num_label) in labels.items()}\n","reverse_index\n"]},{"cell_type":"markdown","id":"fb52e096","metadata":{"id":"fb52e096"},"source":["Now we need to store the data in a Dataset class.  This inherits properties from torch's Dataset class and is what is expected.  It is initialised by giving it dataframe from which it can extract a list of labels and a list of texts.   It handles preprocessing including adding CLS and SEP tokens at the beginning and end, tokenization, lower-casing truncation and padding.  It also provides a `\\_\\_getitem\\_\\_()` method which allows the Dataset to be indexed into like a list i.e., `myDataset[3]` will return a pair which is the label and text with index 3."]},{"cell_type":"code","execution_count":16,"id":"edc90614","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":249,"referenced_widgets":["fc814163b33b4088aa7879be7c42af22","99f27c2ca4024cb18fbb35722c37e99a","2604e48f26b84a9fb6e8791a328d492a","39d4fb22702b469583f4002b9e0e4875","ee001830348b4f029390d24d6981feba","320d024ed454420da1ca9a72a351a8a2","1cf81332ba60444f886b20bf39c966e8","4227d3df665f4420987d1f28ded22bdc","83548d16a65a4f57b302a076cc59be00","92046a2f7494486a80058ea6c4ffd971","8f510ffca00a42f8a203c1503f7ba7e9","1273bca9077541cc9828b6b6ba4d09c2","1920a973376f4234a7547065d3d38b07","cfad98b952da4cb08fad871b227d92d4","47e15ebcdcc84b01bdaabfe980462ece","6dff762e5f5648a293b8707f507add96","fd3fcd3abc044c168db1541659d83f40","8c269fdc91c147c9a32c6453076d0415","c89caa1f65394344bf0c9a1941b7fd64","4571c2d499ec4bec8adc1340e77e4ddd","2683d141270c4d00b7d453e6ee51296d","761651b2c5004d80bc2b69b8dee98502","c15ac52de3fc469ab5ce07d3fb7a0fba","a978b24b005b473ab8c937363753f2b8","9820d373af3749b6a5283db923148588","986befecac9c44b1bb4f50a7ef622bda","3310e4e868374634bc3d0be53cc3206b","b7d8f07fc80f4c4ca1af38e77ec06196","8e44fe6429bf4701920faa82ca40950c","8fe43e1b4cd04233a86525d97b043aa5","699e9e7e36e742c5b4567314c72ad483","a9663778f6534806a301fb3dc742665c","9bf3c3a6119e45ccbf28492e6eb1984d","b601b26aca264c239320190a2d5d721e","14f5c2619d7446b0aa60b331afc4e539","88e0b8a3882c4b5eaac8ccc940f9961f","3e2e216642024e8fbe8a89c1a4331ffe","5e9c76035df4450886e3aa508c5f7bbc","f32dce88f6bc485089e955b6afd7acbe","f37aadfb0844435dba5bb0fcd01247ce","38e7b3c292bb4d1a903c247f9e4bf97c","342da444fec44c56add6566ebce12b15","b0ce384a5d95411b9f783334a4c52daa","cce0b78ea6914433a0fac2f2440402d2"]},"executionInfo":{"elapsed":23946,"status":"ok","timestamp":1713779460096,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"edc90614","outputId":"26bdfb45-9333-4d34-b370-2be4940dcb92"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc814163b33b4088aa7879be7c42af22","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1273bca9077541cc9828b6b6ba4d09c2","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c15ac52de3fc469ab5ce07d3fb7a0fba","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b601b26aca264c239320190a2d5d721e","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import torch\n","import numpy as np\n","from transformers import BertTokenizer, BertModel\n","\n","tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","class Dataset(torch.utils.data.Dataset):\n","\n","    def __init__(self,df,column='text'):\n","        self.labels=[labels[label] for label in df['label']]\n","        self.texts=[tokenizer(text.lower(),padding='max_length',max_length=512,truncation=True,return_tensors=\"pt\") for text in df[column]]\n","\n","    def classes(self):\n","        return self.labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def get_batch_labels(self,idx):\n","        return np.array(self.labels[idx])\n","\n","    def get_batch_texts(self,idx):\n","        return self.texts[idx]\n","\n","    def __getitem__(self,idx):\n","        batch_texts=self.get_batch_texts(idx)\n","        batch_y=self.get_batch_labels(idx)\n","\n","        return batch_texts,batch_y\n","\n","\n","train_data=Dataset(training_df)\n","test_data=Dataset(testing_df)"]},{"cell_type":"code","execution_count":50,"id":"nOTeUiCMWizP","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2777,"status":"ok","timestamp":1713781776062,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"nOTeUiCMWizP","outputId":"d139029e-5f63-4c4c-9ba0-8551ca6afe1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Package                          Version\n","-------------------------------- ---------------------\n","absl-py                          1.4.0\n","aiohttp                          3.9.5\n","aiosignal                        1.3.1\n","alabaster                        0.7.16\n","albumentations                   1.3.1\n","altair                           4.2.2\n","annotated-types                  0.6.0\n","anyio                            3.7.1\n","appdirs                          1.4.4\n","argon2-cffi                      23.1.0\n","argon2-cffi-bindings             21.2.0\n","array_record                     0.5.1\n","arviz                            0.15.1\n","astropy                          5.3.4\n","astunparse                       1.6.3\n","async-timeout                    4.0.3\n","atpublic                         4.1.0\n","attrs                            23.2.0\n","audioread                        3.0.1\n","autograd                         1.6.2\n","Babel                            2.14.0\n","backcall                         0.2.0\n","beautifulsoup4                   4.12.3\n","bidict                           0.23.1\n","bigframes                        1.2.0\n","bleach                           6.1.0\n","blinker                          1.4\n","blis                             0.7.11\n","blosc2                           2.0.0\n","bokeh                            3.3.4\n","bqplot                           0.12.43\n","branca                           0.7.1\n","build                            1.2.1\n","CacheControl                     0.14.0\n","cachetools                       5.3.3\n","catalogue                        2.0.10\n","certifi                          2024.2.2\n","cffi                             1.16.0\n","chardet                          5.2.0\n","charset-normalizer               3.3.2\n","chex                             0.1.86\n","click                            8.1.7\n","click-plugins                    1.1.1\n","cligj                            0.7.2\n","cloudpathlib                     0.16.0\n","cloudpickle                      2.2.1\n","cmake                            3.27.9\n","cmdstanpy                        1.2.2\n","colorcet                         3.1.0\n","colorlover                       0.3.0\n","colour                           0.1.5\n","community                        1.0.0b1\n","confection                       0.1.4\n","cons                             0.4.6\n","contextlib2                      21.6.0\n","contourpy                        1.2.1\n","cryptography                     42.0.5\n","cufflinks                        0.17.3\n","cupy-cuda12x                     12.2.0\n","cvxopt                           1.3.2\n","cvxpy                            1.3.3\n","cycler                           0.12.1\n","cymem                            2.0.8\n","Cython                           3.0.10\n","dask                             2023.8.1\n","datascience                      0.17.6\n","db-dtypes                        1.2.0\n","dbus-python                      1.2.18\n","debugpy                          1.6.6\n","decorator                        4.4.2\n","defusedxml                       0.7.1\n","distributed                      2023.8.1\n","distro                           1.7.0\n","dlib                             19.24.4\n","dm-tree                          0.1.8\n","docstring_parser                 0.16\n","docutils                         0.18.1\n","dopamine-rl                      4.0.6\n","duckdb                           0.10.2\n","earthengine-api                  0.1.399\n","easydict                         1.13\n","ecos                             2.0.13\n","editdistance                     0.6.2\n","eerepr                           0.0.4\n","en-core-web-sm                   3.7.1\n","entrypoints                      0.4\n","et-xmlfile                       1.1.0\n","etils                            1.7.0\n","etuples                          0.3.9\n","exceptiongroup                   1.2.0\n","fastai                           2.7.14\n","fastcore                         1.5.29\n","fastdownload                     0.0.7\n","fastjsonschema                   2.19.1\n","fastprogress                     1.0.3\n","fastrlock                        0.8.2\n","filelock                         3.13.4\n","fiona                            1.9.6\n","firebase-admin                   5.3.0\n","Flask                            2.2.5\n","flatbuffers                      24.3.25\n","flax                             0.8.2\n","folium                           0.14.0\n","fonttools                        4.51.0\n","frozendict                       2.4.2\n","frozenlist                       1.4.1\n","fsspec                           2023.6.0\n","future                           0.18.3\n","gast                             0.5.4\n","gcsfs                            2023.6.0\n","GDAL                             3.4.1\n","gdown                            4.7.3\n","geemap                           0.32.0\n","gensim                           4.3.2\n","geocoder                         1.38.1\n","geographiclib                    2.0\n","geopandas                        0.13.2\n","geopy                            2.3.0\n","gin-config                       0.5.0\n","glob2                            0.7\n","google                           2.0.3\n","google-ai-generativelanguage     0.4.0\n","google-api-core                  2.11.1\n","google-api-python-client         2.84.0\n","google-auth                      2.27.0\n","google-auth-httplib2             0.1.1\n","google-auth-oauthlib             1.2.0\n","google-cloud-aiplatform          1.48.0\n","google-cloud-bigquery            3.12.0\n","google-cloud-bigquery-connection 1.12.1\n","google-cloud-bigquery-storage    2.24.0\n","google-cloud-core                2.3.3\n","google-cloud-datastore           2.15.2\n","google-cloud-firestore           2.11.1\n","google-cloud-functions           1.13.3\n","google-cloud-iam                 2.15.0\n","google-cloud-language            2.13.3\n","google-cloud-resource-manager    1.12.3\n","google-cloud-storage             2.8.0\n","google-cloud-translate           3.11.3\n","google-colab                     1.0.0\n","google-crc32c                    1.5.0\n","google-generativeai              0.3.2\n","google-pasta                     0.2.0\n","google-resumable-media           2.7.0\n","googleapis-common-protos         1.63.0\n","googledrivedownloader            0.4\n","graphviz                         0.20.3\n","greenlet                         3.0.3\n","grpc-google-iam-v1               0.13.0\n","grpcio                           1.62.1\n","grpcio-status                    1.48.2\n","gspread                          3.4.2\n","gspread-dataframe                3.3.1\n","gym                              0.25.2\n","gym-notices                      0.0.8\n","h5netcdf                         1.3.0\n","h5py                             3.9.0\n","holidays                         0.47\n","holoviews                        1.17.1\n","html5lib                         1.1\n","httpimport                       1.3.1\n","httplib2                         0.22.0\n","huggingface-hub                  0.20.3\n","humanize                         4.7.0\n","hyperopt                         0.2.7\n","ibis-framework                   8.0.0\n","idna                             3.7\n","imageio                          2.31.6\n","imageio-ffmpeg                   0.4.9\n","imagesize                        1.4.1\n","imbalanced-learn                 0.10.1\n","imgaug                           0.4.0\n","importlib_metadata               7.1.0\n","importlib_resources              6.4.0\n","imutils                          0.5.4\n","inflect                          7.0.0\n","iniconfig                        2.0.0\n","intel-openmp                     2023.2.4\n","ipyevents                        2.0.2\n","ipyfilechooser                   0.6.0\n","ipykernel                        5.5.6\n","ipyleaflet                       0.18.2\n","ipython                          7.34.0\n","ipython-genutils                 0.2.0\n","ipython-sql                      0.5.0\n","ipytree                          0.2.2\n","ipywidgets                       7.7.1\n","itsdangerous                     2.2.0\n","jax                              0.4.26\n","jaxlib                           0.4.26+cuda12.cudnn89\n","jeepney                          0.7.1\n","jieba                            0.42.1\n","Jinja2                           3.1.3\n","joblib                           1.4.0\n","jsonpickle                       3.0.4\n","jsonschema                       4.19.2\n","jsonschema-specifications        2023.12.1\n","jupyter-client                   6.1.12\n","jupyter-console                  6.1.0\n","jupyter_core                     5.7.2\n","jupyter-server                   1.24.0\n","jupyterlab_pygments              0.3.0\n","jupyterlab_widgets               3.0.10\n","kaggle                           1.5.16\n","kagglehub                        0.2.3\n","keras                            2.15.0\n","keyring                          23.5.0\n","kiwisolver                       1.4.5\n","langcodes                        3.3.0\n","launchpadlib                     1.10.16\n","lazr.restfulclient               0.14.4\n","lazr.uri                         1.0.6\n","lazy_loader                      0.4\n","libclang                         18.1.1\n","librosa                          0.10.1\n","lightgbm                         4.1.0\n","linkify-it-py                    2.0.3\n","llvmlite                         0.41.1\n","locket                           1.0.0\n","logical-unification              0.4.6\n","lxml                             4.9.4\n","malloy                           2023.1067\n","Markdown                         3.6\n","markdown-it-py                   3.0.0\n","MarkupSafe                       2.1.5\n","matplotlib                       3.7.1\n","matplotlib-inline                0.1.7\n","matplotlib-venn                  0.11.10\n","mdit-py-plugins                  0.4.0\n","mdurl                            0.1.2\n","miniKanren                       1.0.3\n","missingno                        0.5.2\n","mistune                          0.8.4\n","mizani                           0.9.3\n","mkl                              2023.2.0\n","ml-dtypes                        0.2.0\n","mlxtend                          0.22.0\n","more-itertools                   10.1.0\n","moviepy                          1.0.3\n","mpmath                           1.3.0\n","msgpack                          1.0.8\n","multidict                        6.0.5\n","multipledispatch                 1.0.0\n","multitasking                     0.0.11\n","murmurhash                       1.0.10\n","music21                          9.1.0\n","natsort                          8.4.0\n","nbclassic                        1.0.0\n","nbclient                         0.10.0\n","nbconvert                        6.5.4\n","nbformat                         5.10.4\n","nest-asyncio                     1.6.0\n","networkx                         3.3\n","nibabel                          4.0.2\n","nltk                             3.8.1\n","notebook                         6.5.5\n","notebook_shim                    0.2.4\n","numba                            0.58.1\n","numexpr                          2.10.0\n","numpy                            1.25.2\n","oauth2client                     4.1.3\n","oauthlib                         3.2.2\n","opencv-contrib-python            4.8.0.76\n","opencv-python                    4.8.0.76\n","opencv-python-headless           4.9.0.80\n","openpyxl                         3.1.2\n","opt-einsum                       3.3.0\n","optax                            0.2.2\n","orbax-checkpoint                 0.4.4\n","osqp                             0.6.2.post8\n","packaging                        24.0\n","pandas                           2.0.3\n","pandas-datareader                0.10.0\n","pandas-gbq                       0.19.2\n","pandas-stubs                     2.0.3.230814\n","pandocfilters                    1.5.1\n","panel                            1.3.8\n","param                            2.1.0\n","parso                            0.8.4\n","parsy                            2.1\n","partd                            1.4.1\n","pathlib                          1.0.1\n","patsy                            0.5.6\n","peewee                           3.17.3\n","pexpect                          4.9.0\n","pickleshare                      0.7.5\n","Pillow                           9.4.0\n","pip                              23.1.2\n","pip-tools                        6.13.0\n","platformdirs                     4.2.0\n","plotly                           5.15.0\n","plotnine                         0.12.4\n","pluggy                           1.4.0\n","polars                           0.20.2\n","pooch                            1.8.1\n","portpicker                       1.5.2\n","prefetch-generator               1.0.3\n","preshed                          3.0.9\n","prettytable                      3.10.0\n","proglog                          0.1.10\n","progressbar2                     4.2.0\n","prometheus_client                0.20.0\n","promise                          2.3\n","prompt-toolkit                   3.0.43\n","prophet                          1.1.5\n","proto-plus                       1.23.0\n","protobuf                         3.20.3\n","psutil                           5.9.5\n","psycopg2                         2.9.9\n","ptyprocess                       0.7.0\n","py-cpuinfo                       9.0.0\n","py4j                             0.10.9.7\n","pyarrow                          14.0.2\n","pyarrow-hotfix                   0.6\n","pyasn1                           0.6.0\n","pyasn1_modules                   0.4.0\n","pycocotools                      2.0.7\n","pycparser                        2.22\n","pydantic                         2.7.0\n","pydantic_core                    2.18.1\n","pydata-google-auth               1.8.2\n","pydot                            1.4.2\n","pydot-ng                         2.0.0\n","pydotplus                        2.0.2\n","PyDrive                          1.3.1\n","PyDrive2                         1.6.3\n","pyerfa                           2.0.1.4\n","pygame                           2.5.2\n","Pygments                         2.16.1\n","PyGObject                        3.42.1\n","PyJWT                            2.3.0\n","pymc                             5.10.4\n","pymystem3                        0.2.0\n","PyOpenGL                         3.1.7\n","pyOpenSSL                        24.1.0\n","pyparsing                        3.1.2\n","pyperclip                        1.8.2\n","pyproj                           3.6.1\n","pyproject_hooks                  1.0.0\n","pyshp                            2.3.1\n","PySocks                          1.7.1\n","pytensor                         2.18.6\n","pytest                           7.4.4\n","python-apt                       0.0.0\n","python-box                       7.1.1\n","python-dateutil                  2.8.2\n","python-louvain                   0.16\n","python-slugify                   8.0.4\n","python-utils                     3.8.2\n","pytz                             2023.4\n","pyviz_comms                      3.0.2\n","PyWavelets                       1.6.0\n","PyYAML                           6.0.1\n","pyzmq                            23.2.1\n","qdldl                            0.1.7.post1\n","qudida                           0.0.4\n","ratelim                          0.1.6\n","referencing                      0.34.0\n","regex                            2023.12.25\n","requests                         2.31.0\n","requests-oauthlib                1.3.1\n","requirements-parser              0.9.0\n","rich                             13.7.1\n","rpds-py                          0.18.0\n","rpy2                             3.4.2\n","rsa                              4.9\n","safetensors                      0.4.3\n","scikit-image                     0.19.3\n","scikit-learn                     1.2.2\n","scipy                            1.11.4\n","scooby                           0.9.2\n","scs                              3.2.4.post1\n","seaborn                          0.13.1\n","SecretStorage                    3.3.1\n","Send2Trash                       1.8.3\n","sentencepiece                    0.1.99\n","setuptools                       67.7.2\n","shapely                          2.0.4\n","six                              1.16.0\n","sklearn-pandas                   2.2.0\n","smart-open                       6.4.0\n","sniffio                          1.3.1\n","snowballstemmer                  2.2.0\n","sortedcontainers                 2.4.0\n","soundfile                        0.12.1\n","soupsieve                        2.5\n","soxr                             0.3.7\n","spacy                            3.7.4\n","spacy-legacy                     3.0.12\n","spacy-loggers                    1.0.5\n","Sphinx                           5.0.2\n","sphinxcontrib-applehelp          1.0.8\n","sphinxcontrib-devhelp            1.0.6\n","sphinxcontrib-htmlhelp           2.0.5\n","sphinxcontrib-jsmath             1.0.1\n","sphinxcontrib-qthelp             1.0.7\n","sphinxcontrib-serializinghtml    1.1.10\n","SQLAlchemy                       2.0.29\n","sqlglot                          20.11.0\n","sqlparse                         0.5.0\n","srsly                            2.4.8\n","stanio                           0.5.0\n","statsmodels                      0.14.2\n","sympy                            1.12\n","tables                           3.8.0\n","tabulate                         0.9.0\n","tbb                              2021.12.0\n","tblib                            3.0.0\n","tenacity                         8.2.3\n","tensorboard                      2.15.2\n","tensorboard-data-server          0.7.2\n","tensorflow                       2.15.0\n","tensorflow-datasets              4.9.4\n","tensorflow-estimator             2.15.0\n","tensorflow-gcs-config            2.15.0\n","tensorflow-hub                   0.16.1\n","tensorflow-io-gcs-filesystem     0.36.0\n","tensorflow-metadata              1.14.0\n","tensorflow-probability           0.23.0\n","tensorstore                      0.1.45\n","termcolor                        2.4.0\n","terminado                        0.18.1\n","text-unidecode                   1.3\n","textblob                         0.17.1\n","tf_keras                         2.15.1\n","tf-slim                          1.1.0\n","thinc                            8.2.3\n","threadpoolctl                    3.4.0\n","tifffile                         2024.2.12\n","tinycss2                         1.2.1\n","tokenizers                       0.15.2\n","toml                             0.10.2\n","tomli                            2.0.1\n","toolz                            0.12.1\n","torch                            2.2.1+cu121\n","torchaudio                       2.2.1+cu121\n","torchdata                        0.7.1\n","torchsummary                     1.5.1\n","torchtext                        0.17.1\n","torchvision                      0.17.1+cu121\n","tornado                          6.3.3\n","tqdm                             4.66.2\n","traitlets                        5.7.1\n","traittypes                       0.2.1\n","transformers                     4.38.2\n","triton                           2.2.0\n","tweepy                           4.14.0\n","typer                            0.9.4\n","types-pytz                       2024.1.0.20240417\n","types-setuptools                 69.5.0.20240415\n","typing_extensions                4.11.0\n","tzdata                           2024.1\n","tzlocal                          5.2\n","uc-micro-py                      1.0.3\n","uritemplate                      4.1.1\n","urllib3                          2.0.7\n","vega-datasets                    0.9.0\n","wadllib                          1.3.6\n","wasabi                           1.1.2\n","wcwidth                          0.2.13\n","weasel                           0.3.4\n","webcolors                        1.13\n","webencodings                     0.5.1\n","websocket-client                 1.7.0\n","Werkzeug                         3.0.2\n","wheel                            0.43.0\n","widgetsnbextension               3.6.6\n","wordcloud                        1.9.3\n","wrapt                            1.14.1\n","xarray                           2023.7.0\n","xarray-einstats                  0.7.0\n","xgboost                          2.0.3\n","xlrd                             2.0.1\n","xyzservices                      2024.4.0\n","yarl                             1.9.4\n","yellowbrick                      1.5\n","yfinance                         0.2.38\n","zict                             3.0.0\n","zipp                             3.18.1\n"]}],"source":["! pip list\n"]},{"cell_type":"markdown","id":"6a398ee6","metadata":{"id":"6a398ee6"},"source":["Lets have a look at one of the dataset items."]},{"cell_type":"markdown","id":"0f93b52f","metadata":{"id":"0f93b52f"},"source":["The \\_\\_getitem\\_\\_ method allows us to index into the dataset and get a particular item"]},{"cell_type":"code","execution_count":17,"id":"cf1b0d3d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1713779460637,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"cf1b0d3d","outputId":"38230d9d-2475-4868-f06b-b3cd9dca7d6e"},"outputs":[{"data":{"text/plain":["({'input_ids': tensor([[  101,  2045, 23481,  1999,  2009,  7132,  2791,  1998, 15003,  1025,\n","           1998,  2065,  1037, 28642,  2063,  1997,  1996,  2088,  1005,  1055,\n","           6620,  2030,  3158,  6447,  2089,  4666,  2007,  2019,  3670,  2061,\n","           8403,  1010,  2129,  2323,  2057,  9610,  3207,  2008,  2029,  2003,\n","           1997,  3011,  2005,  7682,  2070,  6120,  1997,  2049,  2434,  1029,\n","           2146,  1010,  2146,  2097,  1045,  3342,  2115,  2838,  1010,  1998,\n","          19994,  2643,  2008,  1045,  2681,  2026,  7015,  8116,  2121,  2142,\n","           2007,  1011,  1011,  1011,  1005,  1005,  2016,  3030,  2460,  1011,\n","           1011,  1011,  2014,  2159,  3561,  2007,  4000,  1012,   102,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0]])},\n"," array(1))"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["train_data[0]"]},{"cell_type":"markdown","id":"5a9ec8ae","metadata":{"id":"5a9ec8ae"},"source":["We can also jsut look at the text (or label) for an item as follows.  Note that the tokens have been replaced by their indices in the BERT wordpiece vocabulary."]},{"cell_type":"code","execution_count":18,"id":"c5de5d17","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1713779460637,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"c5de5d17","outputId":"0f20181a-d236-415b-d1ec-579639bc162e"},"outputs":[{"data":{"text/plain":["tensor([[  101,  2045, 23481,  1999,  2009,  7132,  2791,  1998, 15003,  1025,\n","          1998,  2065,  1037, 28642,  2063,  1997,  1996,  2088,  1005,  1055,\n","          6620,  2030,  3158,  6447,  2089,  4666,  2007,  2019,  3670,  2061,\n","          8403,  1010,  2129,  2323,  2057,  9610,  3207,  2008,  2029,  2003,\n","          1997,  3011,  2005,  7682,  2070,  6120,  1997,  2049,  2434,  1029,\n","          2146,  1010,  2146,  2097,  1045,  3342,  2115,  2838,  1010,  1998,\n","         19994,  2643,  2008,  1045,  2681,  2026,  7015,  8116,  2121,  2142,\n","          2007,  1011,  1011,  1011,  1005,  1005,  2016,  3030,  2460,  1011,\n","          1011,  1011,  2014,  2159,  3561,  2007,  4000,  1012,   102,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0]])"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["train_data[0][0]['input_ids']"]},{"cell_type":"markdown","id":"8b0ee8af","metadata":{"id":"8b0ee8af"},"source":["### Exercise 4\n","Can you turn the token ids back into subwords for one of the inputs?"]},{"cell_type":"code","execution_count":48,"id":"c04c2d96","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":479,"status":"ok","timestamp":1713781703701,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"c04c2d96","outputId":"d07225df-766b-4880-b80d-15abc1461270"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"there reigns in it gentleness and goodness ; and if a tinge of the world's pride or vanities may mix with an expression so lovely, how should we chide that which is of earth for bearing some colour of its original? long, long will i remember your features, and bless god that i leave my noble deliverer united with - - -'' she stopped short - - - her eyes filled with tears.\""]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["decoded_text = tokenizer.decode(train_data[0][0]['input_ids'].squeeze(), skip_special_tokens=True)\n","decoded_text"]},{"cell_type":"markdown","id":"20aa921d","metadata":{"id":"20aa921d"},"source":["Now we need to prepare the inputs for the particular device (GPU or CPU) that the model is going to be run on.  Let's just check first whether GPU / CUDA has been enabled."]},{"cell_type":"code","execution_count":24,"id":"0f1a4a26","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":471,"status":"ok","timestamp":1713780136507,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"0f1a4a26","outputId":"0f14dec3-cfbb-49e7-f9a1-24abf8204fc6"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU acceleration enabled\n"]}],"source":["use_cuda=torch.cuda.is_available()\n","if use_cuda:\n","  print(\"GPU acceleration enabled\")\n","else:\n","  print(\"GPU acceleration NOT enabled.  If using Colab, have you changed the runtype type and selected GPU as the hardware accelerator?\")\n","device=torch.device(\"cuda\" if use_cuda else \"cpu\")"]},{"cell_type":"code","execution_count":25,"id":"0d5538b8","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1713780136990,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"0d5538b8"},"outputs":[],"source":["def prepare_inputs(input1,label,device):\n","  label=label.to(device)\n","  mask=input1['attention_mask'].to(device)\n","  input_id=input1['input_ids'].squeeze(1).to(device)\n","  return (input_id,mask,label)"]},{"cell_type":"markdown","id":"6fd14229","metadata":{"id":"6fd14229"},"source":["Lets try preparing some inputs and running them through BERT.  We will use the torch DataLoader to manage iterating over the datasets during training and testing.  Here we will just process the first item produced by the DataLoader to see the output from the pre-trained BERT model."]},{"cell_type":"code","execution_count":30,"id":"4046a891","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3016,"status":"ok","timestamp":1713780613604,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"4046a891","outputId":"0616f362-425c-4790-e4f8-f47abd874590"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 101, 2720, 1012,  ...,    0,    0,    0],\n","        [ 101, 2021, 2002,  ...,    0,    0,    0]], device='cuda:0') tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]]], device='cuda:0') tensor([0, 1], device='cuda:0')\n","2\n"]},{"data":{"text/plain":["tensor([[-0.3721, -0.1482, -0.9126,  ..., -0.8406, -0.4007,  0.5815],\n","        [-0.1324, -0.0206, -0.2064,  ..., -0.5971, -0.0908, -0.2047]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import BertModel\n","\n","\n","bert=BertModel.from_pretrained('bert-base-uncased').to(device)\n","\n","for train_input,train_label in train_dataloader:\n","    input_id,mask,label=prepare_inputs(train_input,train_label,device)\n","    output=bert(input_ids=input_id,attention_mask=mask,return_dict=False)\n","    break\n","\n","print(input_id,mask,label)\n","\n","print(len(output))\n","\n","output[1]"]},{"cell_type":"markdown","id":"57417c32","metadata":{"id":"57417c32"},"source":["Now, we need to construct our classification network.  Look at the code below and then answer Exercise 5"]},{"cell_type":"code","execution_count":38,"id":"27208d11","metadata":{"executionInfo":{"elapsed":433,"status":"ok","timestamp":1713781042813,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"27208d11"},"outputs":[],"source":["#now we need to put a simple classification layer on top of BERT\n","\n","from torch import nn\n","from transformers import BertModel\n","\n","class BertClassifier(nn.Module):\n","\n","    def __init__(self,dropout=0.5,num_classes=2):\n","        super(BertClassifier,self).__init__()\n","\n","        self.bert=BertModel.from_pretrained('bert-base-uncased')\n","        self.dropout=nn.Dropout(dropout)\n","        self.linear=nn.Linear(768,num_classes)\n","        self.relu=nn.ReLU()\n","\n","    def forward(self,input_id,mask):\n","\n","        last_hidden_layer,pooled_output = self.bert(input_ids=input_id,attention_mask=mask,return_dict=False)\n","        dropout_output=self.dropout(pooled_output)\n","        linear_output=self.linear(dropout_output)\n","        final_layer=self.relu(linear_output)\n","\n","        return final_layer"]},{"cell_type":"markdown","id":"79c25e73","metadata":{"id":"79c25e73"},"source":["### Exercise 5\n","\n","Use the definitions of the initialisation method and the forward method of the BertClassifier class to sketch out what the neural network architecture looks like.\n","\n","What do you understand by the terms:\n","- pooled output\n","- dropout layer\n","- linear layer\n","- relu layer"]},{"cell_type":"markdown","id":"b1176484","metadata":{"id":"b1176484"},"source":[]},{"cell_type":"markdown","id":"9d671cf0","metadata":{"id":"9d671cf0"},"source":["Next, we define a function which will carry out the training of the network.  It will handle\n","- setting up the DataLoaders\n","- preparing the inputs for CPU / GPU\n","- carrying out training and validation for a number of epochs.  In each epoch:\n","    - iterate over the training data in batches\n","    - get the output for each input and compute the batch loss (Cross Entropy)\n","    - use the batch loss to carry out optimisation\n","    - compute the accuracy and total loss for the training data\n","    - iterate over the testing / validation data in batches\n","    - get the output for each input and compute the batch loss\n","    - compute the accuracy and total loss for the validation data\n","    - output stats"]},{"cell_type":"code","execution_count":39,"id":"a029d919","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1713781047468,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"a029d919"},"outputs":[],"source":["#we now need a training loop\n","\n","from torch.optim import Adam\n","from tqdm import tqdm  #useful library to report on progress through an iteration\n","\n","\n","\n","def train(model, train_data,val_data,learning_rate,epochs):\n","\n","    train_dataloader=torch.utils.data.DataLoader(train_data,batch_size=2,shuffle=True)\n","    val_dataloader=torch.utils.data.DataLoader(test_data,batch_size=2)\n","\n","    use_cuda=torch.cuda.is_available()\n","    device=torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    criterion=nn.CrossEntropyLoss()\n","    optimizer=Adam(model.parameters(),lr=learning_rate)\n","\n","    if use_cuda:\n","        model=model.cuda()\n","        criterion=criterion.cuda()\n","\n","    for epoch_num in range(epochs):\n","        total_acc_train=0\n","        total_loss_train=0\n","        model.train()\n","        for train_input,train_label in tqdm(train_dataloader):\n","\n","            input_id,mask, train_label=prepare_inputs(train_input,train_label,device)\n","\n","            output=model(input_id,mask)\n","\n","            batch_loss=criterion(output,train_label.long())\n","            total_loss_train +=batch_loss.item()\n","\n","            acc=(output.argmax(dim=1)==train_label).sum().item()\n","            total_acc_train+=acc\n","\n","            model.zero_grad()\n","            batch_loss.backward()\n","            optimizer.step()\n","\n","        total_acc_val=0\n","        total_loss_val=0\n","        model.eval()\n","        with torch.no_grad():\n","            for val_input,val_label in val_dataloader:\n","\n","                input_id,mask, val_label=prepare_inputs(val_input,val_label,device)\n","\n","                output=model(input_id,mask)\n","\n","                batch_loss=criterion(output,val_label.long())\n","\n","                total_loss_val+=batch_loss.item()\n","\n","                acc=(output.argmax(dim=1)==val_label).sum().item()\n","                total_acc_val+=acc\n","\n","        print(f'Epochs: {epoch_num+1} | Train Loss: {total_loss_train / len(train_data):.3f} | Train Accuracy: {total_acc_train/len(train_data):.3f}')\n","        print(f'Val loss: {total_loss_val/len(val_data):.3f} | Val Accuracy: {total_acc_val / len(val_data):.3f}')\n"]},{"cell_type":"markdown","id":"015a680a","metadata":{"id":"015a680a"},"source":["Here, we define the number of epochs we are going to train for, the learning rate and an instance of our BertClassifier network."]},{"cell_type":"code","execution_count":41,"id":"26b1084a","metadata":{"executionInfo":{"elapsed":3419,"status":"ok","timestamp":1713781058885,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"26b1084a"},"outputs":[],"source":["EPOCHS=1\n","model=BertClassifier(num_classes=len(labels.keys()))\n","LR=1e-6\n"]},{"cell_type":"markdown","id":"268895e3","metadata":{"id":"268895e3"},"source":["Now we are actually going to train the model.  This might take some time - particularly if you are running on a CPU (1.5hrs per epoch on my laptop!)"]},{"cell_type":"code","execution_count":42,"id":"91a28a8d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":376312,"status":"ok","timestamp":1713781440925,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"91a28a8d","outputId":"f2f8eec3-4a11-4cea-adff-b06fa050a0c4"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|| 1508/1508 [05:45<00:00,  4.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epochs: 1 | Train Loss: 0.270 | Train Accuracy: 0.746\n","Val loss: 0.125 | Val Accuracy: 0.971\n"]}],"source":["train(model,train_data,test_data,LR,EPOCHS)"]},{"cell_type":"markdown","id":"dc2ce954","metadata":{"id":"dc2ce954"},"source":["We need to be able to save the model to be able to use it elsewhere (without training again!)"]},{"cell_type":"code","execution_count":43,"id":"de89eadc","metadata":{"executionInfo":{"elapsed":1141,"status":"ok","timestamp":1713781503207,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"de89eadc"},"outputs":[],"source":["output_dir=\"bert-base-uncased-bookclassifier\"\n","torch.save(model,output_dir)"]},{"cell_type":"markdown","id":"f0505fa1","metadata":{"id":"f0505fa1"},"source":["We can load it up like this.  This could be in another notebook.  If loading in another notebook, you should make sure the BertClassifier class is also defined in that notebook (along with other necessary imports).\n","\n","My trained bert-base-uncased-bookclassifier is included in the resources directory as `julie-bert-base-uncased-bookclassifier`.  Use this if you don't have access to GPU to train your own model.  Note it is a large file (around 0.5Gb)"]},{"cell_type":"code","execution_count":44,"id":"53142ebe","metadata":{"executionInfo":{"elapsed":413,"status":"ok","timestamp":1713781505292,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"53142ebe"},"outputs":[],"source":["input_dir=\"bert-base-uncased-bookclassifier\"\n","#input_dir =\"julie-bert-base-uncased-bookclassifier\"\n","complete_model=torch.load(input_dir)"]},{"cell_type":"markdown","id":"ba96b83d","metadata":{"id":"ba96b83d"},"source":["Here's an evaluation loop we can use to evaluate on some test data.  We also return the predictions which can than be added to the dataframe"]},{"cell_type":"code","execution_count":45,"id":"bcaa0506","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1713781508566,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"bcaa0506"},"outputs":[],"source":["batchsize=2\n","def evaluate(model,test_dataset):\n","    model.eval()\n","    test_dataloader=torch.utils.data.DataLoader(test_dataset,batch_size=batchsize)\n","\n","    use_cuda=torch.cuda.is_available()\n","    device=torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    if use_cuda:\n","        model=model.cuda()\n","\n","    total_acc_test=0\n","    with torch.no_grad():\n","        count=0\n","        predictions=[]\n","        for test_input,test_label in tqdm(test_dataloader):\n","            count+=batchsize\n","            test_label=test_label.to(device)\n","            mask=test_input['attention_mask'].to(device)\n","            input_id=test_input['input_ids'].squeeze(1).to(device)\n","            output=model(input_id,mask)\n","            #print(output.argmax(dim=1),test_label)\n","            predictions.append(output.argmax(dim=1))  #save the prediction for further analysis\n","            acc=(output.argmax(dim=1)==test_label).sum().item()\n","\n","            total_acc_test+=acc\n","            if count%100==0:\n","                print(f'Accuracy so far = {total_acc_test/count: .3f}')\n","\n","    print(f'Test accuracy: {total_acc_test/len(test_dataset): .3f}')\n","    return predictions"]},{"cell_type":"markdown","id":"c76b9d19","metadata":{"id":"c76b9d19"},"source":["This takes around 6 minutes to run on my laptop.  I have the evaluation loop printing out \"Accuracy so far\" as I get bored waiting to the end to see the results - it also gives a very rough indication of how stable the method is"]},{"cell_type":"code","execution_count":46,"id":"2f8c8f47","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30587,"status":"ok","timestamp":1713781543982,"user":{"displayName":"RF Davey","userId":"16144606577079530867"},"user_tz":-60},"id":"2f8c8f47","outputId":"813c4694-b0bf-47fd-bfc7-6dcbffbc5872"},"outputs":[{"name":"stderr","output_type":"stream","text":[" 14%|        | 52/378 [00:03<00:25, 12.91it/s]"]},{"name":"stdout","output_type":"stream","text":["Accuracy so far =  0.960\n"]},{"name":"stderr","output_type":"stream","text":[" 27%|       | 102/378 [00:07<00:21, 12.70it/s]"]},{"name":"stdout","output_type":"stream","text":["Accuracy so far =  0.965\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|      | 152/378 [00:11<00:18, 12.42it/s]"]},{"name":"stdout","output_type":"stream","text":["Accuracy so far =  0.943\n"]},{"name":"stderr","output_type":"stream","text":[" 53%|    | 202/378 [00:15<00:14, 12.34it/s]"]},{"name":"stdout","output_type":"stream","text":["Accuracy so far =  0.958\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|   | 252/378 [00:20<00:10, 12.23it/s]"]},{"name":"stdout","output_type":"stream","text":["Accuracy so far =  0.966\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|  | 302/378 [00:24<00:06, 11.96it/s]"]},{"name":"stdout","output_type":"stream","text":["Accuracy so far =  0.972\n"]},{"name":"stderr","output_type":"stream","text":[" 93%|| 352/378 [00:28<00:02, 11.93it/s]"]},{"name":"stdout","output_type":"stream","text":["Accuracy so far =  0.970\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 378/378 [00:30<00:00, 12.39it/s]"]},{"name":"stdout","output_type":"stream","text":["Test accuracy:  0.971\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["predictions=evaluate(model, test_data)"]},{"cell_type":"markdown","id":"6e89f1f5","metadata":{"id":"6e89f1f5"},"source":["### Exercise 6\n","Add the predicted label for each test item to the dataframe with the test data."]},{"cell_type":"code","execution_count":null,"id":"902fa64b","metadata":{"id":"902fa64b"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"397f6c55","metadata":{"id":"397f6c55"},"source":["### Exercise 7\n","Compute the confusion matrix / precision and recall scores for the different classes.  What does this analysis tell you about the errors?"]},{"cell_type":"code","execution_count":null,"id":"b11ab031","metadata":{"id":"b11ab031"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"1a891941","metadata":{"id":"1a891941"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"f4047999","metadata":{"id":"f4047999"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"a02628eb","metadata":{"id":"a02628eb"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"4ff407f5","metadata":{"id":"4ff407f5"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"541d04ee","metadata":{"id":"541d04ee"},"source":[]},{"cell_type":"markdown","id":"1d9f8dce","metadata":{"id":"1d9f8dce"},"source":["### Extension 1\n","Carry out some more detailed error analysis.  Look at examples where the class is incorrectly predicted.  Do you notice anything that the examples have in common (e.g., length, vocabulary, structure).  Can you quantify the number of errors that this effect might account for?"]},{"cell_type":"code","execution_count":null,"id":"3f113377","metadata":{"id":"3f113377"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"4583dbf1","metadata":{"id":"4583dbf1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"91976a7b","metadata":{"id":"91976a7b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"a72248a7","metadata":{"id":"a72248a7"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"9584ae91","metadata":{"id":"9584ae91"},"source":["### Extension 2\n","Some might say that it is easier to distinguish these books due to particular vocabulary e.g., character names (Emma and Ivanhoe!)\n","Compare the performance of the BertClassifier with a Nave Bayes classifier."]},{"cell_type":"code","execution_count":null,"id":"fab86902","metadata":{"id":"fab86902"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"f476397f","metadata":{"id":"f476397f"},"source":["### Extension 3\n","Look at some more pairs of books (e.g., 4 pairs of books).  Are you able to identify pairs of books which are easier or harder than others to distinguish?"]},{"cell_type":"code","execution_count":null,"id":"1f980071","metadata":{"id":"1f980071"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"d240dc84","metadata":{"id":"d240dc84"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"6b11e0d7","metadata":{"id":"6b11e0d7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"e5fa762d","metadata":{"id":"e5fa762d"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"8ca50814","metadata":{"id":"8ca50814"},"source":["### Extension 4\n","Choose 5 books and build a 5-way classifier to distinguish between them.  Evaluate your classifier and carry out some basic error analysis as before."]},{"cell_type":"code","execution_count":null,"id":"c66bfff1","metadata":{"id":"c66bfff1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"6d6bac38","metadata":{"id":"6d6bac38"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"7a5050c7","metadata":{"id":"7a5050c7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"d94a231b","metadata":{"id":"d94a231b"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1273bca9077541cc9828b6b6ba4d09c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1920a973376f4234a7547065d3d38b07","IPY_MODEL_cfad98b952da4cb08fad871b227d92d4","IPY_MODEL_47e15ebcdcc84b01bdaabfe980462ece"],"layout":"IPY_MODEL_6dff762e5f5648a293b8707f507add96"}},"14f5c2619d7446b0aa60b331afc4e539":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f32dce88f6bc485089e955b6afd7acbe","placeholder":"","style":"IPY_MODEL_f37aadfb0844435dba5bb0fcd01247ce","value":"config.json:100%"}},"1920a973376f4234a7547065d3d38b07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd3fcd3abc044c168db1541659d83f40","placeholder":"","style":"IPY_MODEL_8c269fdc91c147c9a32c6453076d0415","value":"vocab.txt:100%"}},"1cf81332ba60444f886b20bf39c966e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2604e48f26b84a9fb6e8791a328d492a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4227d3df665f4420987d1f28ded22bdc","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_83548d16a65a4f57b302a076cc59be00","value":48}},"2683d141270c4d00b7d453e6ee51296d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"320d024ed454420da1ca9a72a351a8a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3310e4e868374634bc3d0be53cc3206b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"342da444fec44c56add6566ebce12b15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"38e7b3c292bb4d1a903c247f9e4bf97c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39d4fb22702b469583f4002b9e0e4875":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92046a2f7494486a80058ea6c4ffd971","placeholder":"","style":"IPY_MODEL_8f510ffca00a42f8a203c1503f7ba7e9","value":"48.0/48.0[00:00&lt;00:00,3.37kB/s]"}},"3e2e216642024e8fbe8a89c1a4331ffe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0ce384a5d95411b9f783334a4c52daa","placeholder":"","style":"IPY_MODEL_cce0b78ea6914433a0fac2f2440402d2","value":"570/570[00:00&lt;00:00,38.0kB/s]"}},"4227d3df665f4420987d1f28ded22bdc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4571c2d499ec4bec8adc1340e77e4ddd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"47e15ebcdcc84b01bdaabfe980462ece":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2683d141270c4d00b7d453e6ee51296d","placeholder":"","style":"IPY_MODEL_761651b2c5004d80bc2b69b8dee98502","value":"232k/232k[00:00&lt;00:00,1.01MB/s]"}},"5e9c76035df4450886e3aa508c5f7bbc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"699e9e7e36e742c5b4567314c72ad483":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6dff762e5f5648a293b8707f507add96":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"761651b2c5004d80bc2b69b8dee98502":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83548d16a65a4f57b302a076cc59be00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88e0b8a3882c4b5eaac8ccc940f9961f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_38e7b3c292bb4d1a903c247f9e4bf97c","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_342da444fec44c56add6566ebce12b15","value":570}},"8c269fdc91c147c9a32c6453076d0415":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e44fe6429bf4701920faa82ca40950c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f510ffca00a42f8a203c1503f7ba7e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8fe43e1b4cd04233a86525d97b043aa5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92046a2f7494486a80058ea6c4ffd971":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9820d373af3749b6a5283db923148588":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fe43e1b4cd04233a86525d97b043aa5","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_699e9e7e36e742c5b4567314c72ad483","value":466062}},"986befecac9c44b1bb4f50a7ef622bda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9663778f6534806a301fb3dc742665c","placeholder":"","style":"IPY_MODEL_9bf3c3a6119e45ccbf28492e6eb1984d","value":"466k/466k[00:00&lt;00:00,651kB/s]"}},"99f27c2ca4024cb18fbb35722c37e99a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_320d024ed454420da1ca9a72a351a8a2","placeholder":"","style":"IPY_MODEL_1cf81332ba60444f886b20bf39c966e8","value":"tokenizer_config.json:100%"}},"9bf3c3a6119e45ccbf28492e6eb1984d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a9663778f6534806a301fb3dc742665c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a978b24b005b473ab8c937363753f2b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7d8f07fc80f4c4ca1af38e77ec06196","placeholder":"","style":"IPY_MODEL_8e44fe6429bf4701920faa82ca40950c","value":"tokenizer.json:100%"}},"b0ce384a5d95411b9f783334a4c52daa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b601b26aca264c239320190a2d5d721e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_14f5c2619d7446b0aa60b331afc4e539","IPY_MODEL_88e0b8a3882c4b5eaac8ccc940f9961f","IPY_MODEL_3e2e216642024e8fbe8a89c1a4331ffe"],"layout":"IPY_MODEL_5e9c76035df4450886e3aa508c5f7bbc"}},"b7d8f07fc80f4c4ca1af38e77ec06196":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c15ac52de3fc469ab5ce07d3fb7a0fba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a978b24b005b473ab8c937363753f2b8","IPY_MODEL_9820d373af3749b6a5283db923148588","IPY_MODEL_986befecac9c44b1bb4f50a7ef622bda"],"layout":"IPY_MODEL_3310e4e868374634bc3d0be53cc3206b"}},"c89caa1f65394344bf0c9a1941b7fd64":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cce0b78ea6914433a0fac2f2440402d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfad98b952da4cb08fad871b227d92d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c89caa1f65394344bf0c9a1941b7fd64","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4571c2d499ec4bec8adc1340e77e4ddd","value":231508}},"ee001830348b4f029390d24d6981feba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f32dce88f6bc485089e955b6afd7acbe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f37aadfb0844435dba5bb0fcd01247ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc814163b33b4088aa7879be7c42af22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99f27c2ca4024cb18fbb35722c37e99a","IPY_MODEL_2604e48f26b84a9fb6e8791a328d492a","IPY_MODEL_39d4fb22702b469583f4002b9e0e4875"],"layout":"IPY_MODEL_ee001830348b4f029390d24d6981feba"}},"fd3fcd3abc044c168db1541659d83f40":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":5}
